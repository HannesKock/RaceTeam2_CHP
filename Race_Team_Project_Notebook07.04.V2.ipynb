{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannesKock/RaceTeam2_CHP/blob/main/Race_Team_Project_Notebook07.04.V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycXWv5-jYpIC"
      },
      "source": [
        "# **Race Team Project Notebook**\n",
        "Names:\n",
        "\n",
        "Matr.:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUOq9_tORt3e"
      },
      "source": [
        "Please write down the Name of the Group member you worked on each section of code. This is necessary for grading by Studienbüro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8aiLYHdaX9P"
      },
      "source": [
        "## **Analytics for Race 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuIPnDlucl2q"
      },
      "source": [
        "- For each race day built one section with the code that you built for this race\n",
        "- If you keep the same code during the next races copy the code over to the next section\n",
        "- Describe why you built your analytics the way you do and interprete after each race what went well and what you want to improve on\n",
        "- During motivation and interpretation try to cite online sources that you read to make better decisions (e.g., scientific articles on machine learning, blog posts, github pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhtO3nrmQL5S"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Paula, Cedric, Hannes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Daten einlesen & Überblick verschaffen\n",
        "#https://www.datacamp.com/tutorial/pandas-read-csv\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "print(df.describe())\n",
        "print(df.info())\n"
      ],
      "metadata": {
        "id": "rQ78TqIW1vi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots (Parameter vs. Rundenzeit)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "param_cols = df.columns.drop(\"Lap Time\")\n",
        "\n",
        "for col in param_cols:\n",
        "    plt.figure()\n",
        "    sns.scatterplot(x=df[col], y=df[\"Lap Time\"], alpha=0.3)\n",
        "    plt.title(f\"{col} vs. Lap Time\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "L1t83oN149ZJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots (Parameter vs. Avg. Speed)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Durchschnittsgeschwindigkeit berechnen (falls noch nicht vorhanden)\n",
        "if \"Avg. Speed\" not in df.columns:\n",
        "    df[\"Avg. Speed\"] = df[\"Lap Distance\"] / (df[\"Lap Time\"] / 3600)\n",
        "\n",
        "# Alle Spalten außer \"Lap Time\" und \"Avg. Speed\" verwenden\n",
        "param_cols = df.columns.drop([\"Lap Time\", \"Avg. Speed\"])\n",
        "\n",
        "# Scatterplots erzeugen\n",
        "for col in param_cols:\n",
        "    plt.figure()\n",
        "    sns.scatterplot(x=df[col], y=df[\"Avg. Speed\"], alpha=0.3)\n",
        "    plt.title(f\"{col} vs. Avg. Speed\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Avg. Speed (km/h)\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "83ZAwsoP_YTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import optuna\n",
        "\n",
        "# === 1. Daten einlesen ===\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Ziel- und Feature-Spalten\n",
        "target_col = \"Lap Time\"\n",
        "feature_cols = df.columns.drop(target_col)\n",
        "\n",
        "# === 2. Modell trainieren ===\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "# Optional: Skalieren\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Training/Test-Split (z. B. für Validierung)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === 3. Bayesian Optimization Setup (Optuna) ===\n",
        "\n",
        "# Gegeben: Umgebungsbedingungen\n",
        "fixed_conditions = {\n",
        "    'Lap Distance': 3.7,\n",
        "    'Cornering': 6,\n",
        "    'Inclines': 20,\n",
        "    'Camber': 44,\n",
        "    'Grip': 1,\n",
        "    'Wind (Avg. Speed)': 97,\n",
        "    'Temperature': 29,\n",
        "    'Humidity': 23,\n",
        "    'Air Density': 70,\n",
        "    'Air Pressure': 98,\n",
        "    'Wind (Gusts)': 49,\n",
        "    'Altitude': 31,\n",
        "    'Roughness': 49,\n",
        "    'Width': 29\n",
        "}\n",
        "\n",
        "def objective(trial):\n",
        "    # Optimierbare Fahrzeugparameter\n",
        "    params = {\n",
        "        'Rear Wing': trial.suggest_float('Rear Wing', 0.0, 500),\n",
        "        'Engine': trial.suggest_float('Engine', 0.0, 500),\n",
        "        'Front Wing': trial.suggest_float('Front Wing', 0.0, 500),\n",
        "        'Brake Balance': trial.suggest_float('Brake Balance', 0.0, 500),\n",
        "        'Differential': trial.suggest_float('Differential', 0.0, 500),\n",
        "        'Suspension': trial.suggest_float('Suspension', 0.0, 500),\n",
        "    }\n",
        "\n",
        "    # Kombinieren mit festen Bedingungen\n",
        "    full_input = {**fixed_conditions, **params}\n",
        "    X_input = pd.DataFrame([full_input])\n",
        "    X_input_scaled = scaler.transform(X_input)\n",
        "\n",
        "    # Vorhersage durch Modell\n",
        "    lap_time = model.predict(X_input_scaled)[0]\n",
        "    return lap_time\n",
        "\n",
        "# Optuna-Studie starten\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Ergebnisse\n",
        "print(\"Beste Parameterkombination:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n",
        "print(f\"Erwartete Rundenzeit: {study.best_value:.4f} Sekunden\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "a9HOY9CO106A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy  as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Falls noch nicht geschehen: Durchschnittsgeschwindigkeit berechnen\n",
        "if \"Avg. Speed\" not in df.columns:\n",
        "    df[\"Avg. Speed\"] = df[\"Lap Distance\"] / (df[\"Lap Time\"] / 3600)\n",
        "\n",
        "# 2. Features & Ziel definieren\n",
        "feature_cols = [\n",
        "    'Lap Distance', 'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width',\n",
        "    'Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential',\n",
        "    'Suspension'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"Avg. Speed\"]\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# 4. Modell trainieren (XGBoost)\n",
        "#model = xgb.XGBRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "model = xgb.XGBRegressor(colsample_bytree=1.0, learning_rate = 0.05, max_depth = 6, min_child_weight = 1, n_estimators = 300, subsample = 0.8)\n",
        "model.fit(X_train, y_train)\n",
        "y_hat = model.predict(X_test)\n",
        "error = np.mean(np.abs(y_test - y_hat))\n",
        "print(error)\n",
        "\n",
        "# # 5. SHAP-Werte berechnen\n",
        "explainer = shap.Explainer(model)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# # 6. SHAP Summary Plot\n",
        "shap.summary_plot(shap_values, X_test)\n"
      ],
      "metadata": {
        "id": "_4C7T1BhGyGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# You can get this from df.mean().values or pick a sample row\n",
        "base_input = df[feature_cols].mean().values\n",
        "\n",
        "for fc in fixed_conditions:\n",
        "    base_input[feature_cols.index(fc)] = fixed_conditions[fc]\n",
        "\n",
        "# Indices of the features we want to optimize\n",
        "optim_features = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "optim_indices = [feature_cols.index(f) for f in optim_features]\n",
        "\n",
        "# Define bounds from your dataset (here we use min/max)\n",
        "feature_bounds = {\n",
        "    'Rear Wing': (1, 500),\n",
        "    'Engine': (1, 500),\n",
        "    'Front Wing': (1, 500),\n",
        "    'Brake Balance': (1, 500),\n",
        "    'Differential': (1, 500),\n",
        "    'Suspension': (1, 500),\n",
        "}\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    x = base_input.copy()\n",
        "\n",
        "    for f in optim_features:\n",
        "        val = trial.suggest_int(f, int(feature_bounds[f][0]), int(feature_bounds[f][1]))\n",
        "        x[feature_cols.index(f)] = val\n",
        "\n",
        "    pred = model.predict(np.array([x]))[0]\n",
        "    return pred  # Optuna will maximize if we tell it to\n",
        "\n",
        "# Run Optuna study\n",
        "optuna.logging.disable_default_handler()\n",
        "study = optuna.create_study(direction='maximize')  # use 'minimize' if lower lap time is better\n",
        "study.optimize(objective, n_trials=255)\n",
        "\n",
        "\n",
        "# Show results\n",
        "print(\"Best params:\")\n",
        "for k, v in study.best_params.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "print(f\"Max predicted avg speed: {study.best_value}\")\n"
      ],
      "metadata": {
        "id": "6v_W-wPAUbrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grid Search for best Model Parameters\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Create the target variable: average speed\n",
        "df['Avg Speed'] = df['Lap Distance'] / df['Lap Time']\n",
        "\n",
        "# Drop unused columns\n",
        "X = df.drop(columns=['Lap Distance', 'Lap Time', 'Avg Speed'])\n",
        "y = df['Avg Speed']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define XGBoost Regressor\n",
        "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Define grid search parameters\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [100, 300],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'min_child_weight': [1, 5]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "jJHJ_frRk-Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determining, which Parameters have the biggest impacts on Lap Times / Speeds.\n",
        "\n",
        "\n",
        "\n",
        "This code trains an XGBoost Regressor model to predict the average speed of a car based on various track and environmental features. First, it loads the data and calculates the average speed by dividing the lap distance by the lap time. The code then preprocesses the data by removing unnecessary columns and splits it into training and testing sets. After training the model, it evaluates the feature importances to determine which variables most strongly influence the predicted average speed. **Finally, it plots a bar chart to visually display the feature importances, providing insights into the relative impact of each feature.**"
      ],
      "metadata": {
        "id": "CL-Q4Cb9qo6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = df[\"Lap Distance\"] / df[\"Lap Time\"]\n",
        "\n",
        "X = df.drop(columns=[\"Lap Distance\", \"Lap Time\", \"Avg Speed\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = XGBRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Plot feature importance\n",
        "importances = model.feature_importances_\n",
        "feat_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "feat_importance.plot(kind=\"bar\", figsize=(12, 6), title=\"Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lgr-Ysmx0tl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determining, which Track/Weather Parameters have the biggest impacts on each car parameter\n",
        "\n",
        "This code performs feature importance analysis for various car setup parameters based on environmental and track/weather conditions. It uses the XGBoost Regressor to model the relationship between the track/weather variables and each car setup parameter. The data is split into training and test sets, and the model is evaluated using the R² score to measure prediction accuracy. After training, the code extracts and plots the feature importances for each car parameter, helping to identify which track/weather variables have the most significant impact on each car setup."
      ],
      "metadata": {
        "id": "jhlF9wcwouWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Define inputs (environmental variables) and targets (car parameters)\n",
        "track_weather_features = [\n",
        "    'Lap Distance', 'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width'\n",
        "]\n",
        "\n",
        "car_setup_params = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "\n",
        "# Store results\n",
        "feature_importance_dict = {}\n",
        "\n",
        "for param in car_setup_params:\n",
        "    X = df[track_weather_features]\n",
        "    y = df[param]\n",
        "\n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n {param} - R²: {score:.3f}\")\n",
        "\n",
        "    # Feature importances\n",
        "    importances = model.feature_importances_\n",
        "    importance_series = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "    feature_importance_dict[param] = importance_series\n",
        "\n",
        "    # Plot\n",
        "    importance_series.plot(kind='barh', title=f\"Feature Importance for {param}\", figsize=(8, 5))\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "rtdkTCEw4721"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Define inputs (track/weather features) and targets (car parameters)\n",
        "track_weather_features = [\n",
        "    'Lap Distance', 'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width'\n",
        "]\n",
        "\n",
        "car_setup_params = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "\n",
        "# Store feature importances for each car parameter\n",
        "feature_importance_dict = {}\n",
        "\n",
        "# Loop through car parameters\n",
        "for param in car_setup_params:\n",
        "    X = df[track_weather_features]\n",
        "    y = df[param]\n",
        "\n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate R² score\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n{param} - R²: {score:.3f}\")\n",
        "\n",
        "    # Get feature importances and filter by importance > 0.1\n",
        "    importances = model.feature_importances_\n",
        "    importance_series = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Store importances\n",
        "    feature_importance_dict[param] = importance_series\n",
        "\n",
        "    # Display the features with importance > 0.1\n",
        "    print(f\"\\nFor {param}, track/weather parameters with importance > 0.1:\")\n",
        "    for feature, importance in importance_series.items():\n",
        "        if importance > 0.075:\n",
        "            print(f\" - {feature}: {importance:.3f}\")\n",
        "\n",
        "    # Optional: Plot feature importances\n",
        "    importance_series.plot(kind='barh', title=f\"Feature Importance for {param}\", figsize=(8, 5))\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "piDIG5ojfAUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Define inputs (track/weather features) and targets (car parameters)\n",
        "track_weather_features = [\n",
        "    'Lap Distance', 'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width'\n",
        "]\n",
        "\n",
        "car_setup_params = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "\n",
        "# Store feature importances for each car parameter\n",
        "feature_importance_dict = {}\n",
        "\n",
        "# Loop through car parameters\n",
        "for param in car_setup_params:\n",
        "    # Include track/weather features and other car parameters (excluding the target parameter itself)\n",
        "    other_car_params = [p for p in car_setup_params if p != param]\n",
        "    X = df[track_weather_features + other_car_params]\n",
        "    y = df[param]\n",
        "\n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate R² score\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n{param} - R²: {score:.3f}\")\n",
        "\n",
        "    # Get feature importances and sort them\n",
        "    importances = model.feature_importances_\n",
        "    importance_series = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Store importances\n",
        "    feature_importance_dict[param] = importance_series\n",
        "\n",
        "    # Display the features with importance > 0.075\n",
        "    print(f\"\\nFor {param}, all parameters with importance > 0.075:\")\n",
        "    for feature, importance in importance_series.items():\n",
        "        if importance > 0.075:\n",
        "            print(f\" - {feature}: {importance:.3f}\")\n",
        "\n",
        "    # Optional: Plot feature importances\n",
        "    importance_series.plot(kind='barh', title=f\"Feature Importance for {param}\", figsize=(8, 5))\n",
        "    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "D3kuj_jRFkln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FR-MJQxykiEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sequential optimization of car-parameters. **\n",
        "\n",
        "We optimize each Car-parameter in a predefined order, ensuring that each optimization builds upon the previous ones. (Order: Feature Importance (highest to lowest)(see above))\n",
        "\n",
        "For each car parameter, we first train a predictive model for average speed using relevant track/weather variables and already optimized parameters. Then, using Optuna, we search for the optimal value of the current car parameter that maximizes the predicted average speed.\n",
        "\n",
        "What track and wheather parameters are important for each Car-Parameter was determined before (see above)\n",
        "\n",
        "Order of optimization and relevant track/weather parameters:\n",
        "\n",
        "1. Engine: Grip, Altitude, Humidity, Air Density, Temperature, Air Pressure, Inclines\n",
        "2. Differetial: Cornering, Width, Inclines, Grip, Temprature, Air Density\n",
        "3. Rear Wing: Air Pressure, Air Density, Cornering, Inclines, Wind (Avg. Speed), Humidity, Roughness\n",
        "4. Break Balance: Width, Cornering, Roughness, Temperature\n",
        "5. Front Wing: Air Pressure, Cornering, Air Density, Inclines, Wind (Avg. Speed), Humidity, Wind (Gusts)\n",
        "6. Suspension: Grip, Inclines, Cornering, Camber, Width, Roughness\n"
      ],
      "metadata": {
        "id": "1HSUU_WOlmll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Fixed track & weather settings — user-defined!\n",
        "fixed_conditions = {\n",
        "    \"Cornering\": 6,\n",
        "    \"Inclines\": 20,\n",
        "    \"Camber\": 44,\n",
        "    \"Grip\": 1,\n",
        "    \"Altitude\": 31,\n",
        "    \"Roughness\": 49,\n",
        "    \"Width\": 29,\n",
        "    \"Temperature\": 29,\n",
        "    \"Humidity\": 23,\n",
        "    \"Wind (Avg. Speed)\": 97,\n",
        "    \"Wind (Gusts)\": 49,\n",
        "    \"Air Density\": 70,\n",
        "    \"Air Pressure\": 98,\n",
        "}\n",
        "\n",
        "# Order of optimization and relevant features\n",
        "optimization_order = [\n",
        "    (\"Engine\", [\"Grip\", \"Altitude\", \"Humidity\", \"Air Density\", \"Temperature\", \"Air Pressure\", \"Inclines\"]),\n",
        "    (\"Differential\", [\"Cornering\", \"Width\", \"Inclines\", \"Grip\", \"Temperature\", \"Air Density\"]),\n",
        "    (\"Rear Wing\", [\"Air Pressure\", \"Air Density\", \"Cornering\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Roughness\"]),\n",
        "    (\"Brake Balance\", [\"Width\", \"Cornering\", \"Roughness\", \"Temperature\"]),\n",
        "    (\"Front Wing\", [\"Air Pressure\", \"Cornering\", \"Air Density\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Wind (Gusts)\"]),\n",
        "    (\"Suspension\", [\"Grip\", \"Inclines\", \"Cornering\", \"Camber\", \"Width\", \"Roughness\"]),\n",
        "]\n",
        "\n",
        "# Storage for optimized parameters\n",
        "optimized_params = {}\n",
        "\n",
        "\n",
        "# Optimization loop\n",
        "for param, relevant_features in optimization_order:\n",
        "    print(f\"\\n Optimizing {param}...\")\n",
        "\n",
        "    # Features for model = track/weather + already optimized + current param\n",
        "    model_features = relevant_features + list(optimized_params.keys()) + [param]\n",
        "    model_df = df[model_features + [\"Avg Speed\"]].dropna()\n",
        "\n",
        "    X = model_df[model_features]\n",
        "    y = model_df[\"Avg Speed\"]\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Prepare fixed input for this stage\n",
        "    input_row = {f: fixed_conditions[f] for f in relevant_features}\n",
        "    input_row.update(optimized_params)  # Include already optimized parameters\n",
        "\n",
        "    def objective(trial):\n",
        "        trial_value = trial.suggest_int(param, 1, 500)\n",
        "        row = input_row.copy()\n",
        "        row[param] = trial_value\n",
        "        df_input = pd.DataFrame([row])\n",
        "        pred = model.predict(df_input)[0]\n",
        "        return pred  # Maximizing Avg Speed\n",
        "\n",
        "    optuna.logging.disable_default_handler()\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "    print(f\"Max predicted avg speed: {study.best_value}\")\n",
        "\n",
        "    best_val = study.best_params[param]\n",
        "    optimized_params[param] = best_val\n",
        "\n",
        "    print(f\" Best {param}: {best_val}\")\n",
        "\n",
        "# Final output\n",
        "print(\"\\n All optimized parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "Lu2xXtIKRJMF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Fixed track & weather settings — user-defined!\n",
        "fixed_conditions = {\n",
        "    \"Cornering\": 6,\n",
        "    \"Inclines\": 20,\n",
        "    \"Camber\": 44,\n",
        "    \"Grip\": 1,\n",
        "    \"Altitude\": 31,\n",
        "    \"Roughness\": 49,\n",
        "    \"Width\": 29,\n",
        "    \"Temperature\": 29,\n",
        "    \"Humidity\": 23,\n",
        "    \"Wind (Avg. Speed)\": 97,\n",
        "    \"Wind (Gusts)\": 49,\n",
        "    \"Air Density\": 70,\n",
        "    \"Air Pressure\": 98,\n",
        "}\n",
        "\n",
        "# Order of optimization and relevant features\n",
        "optimization_order = [\n",
        "    (\"Suspension\", [\"Grip\", \"Inclines\", \"Cornering\", \"Camber\", \"Width\", \"Roughness\"]),\n",
        "    (\"Front Wing\", [\"Air Pressure\", \"Cornering\", \"Air Density\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Wind (Gusts)\"]),\n",
        "    (\"Brake Balance\", [\"Width\", \"Cornering\", \"Roughness\", \"Temperature\"]),\n",
        "    (\"Rear Wing\", [\"Air Pressure\", \"Air Density\", \"Cornering\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Roughness\"]),\n",
        "    (\"Differential\", [\"Cornering\", \"Width\", \"Inclines\", \"Grip\", \"Temperature\", \"Air Density\"]),\n",
        "    (\"Engine\", [\"Grip\", \"Altitude\", \"Humidity\", \"Air Density\", \"Temperature\", \"Air Pressure\", \"Inclines\"])\n",
        "]\n",
        "\n",
        "# Storage for optimized parameters\n",
        "optimized_params = {}\n",
        "\n",
        "\n",
        "# Optimization loop\n",
        "for param, relevant_features in optimization_order:\n",
        "    print(f\"\\n Optimizing {param}...\")\n",
        "\n",
        "    # Features for model = track/weather + already optimized + current param\n",
        "    model_features = relevant_features + list(optimized_params.keys()) + [param]\n",
        "    model_df = df[model_features + [\"Avg Speed\"]].dropna()\n",
        "\n",
        "    X = model_df[model_features]\n",
        "    y = model_df[\"Avg Speed\"]\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Prepare fixed input for this stage\n",
        "    input_row = {f: fixed_conditions[f] for f in relevant_features}\n",
        "    input_row.update(optimized_params)  # Include already optimized parameters\n",
        "\n",
        "    def objective(trial):\n",
        "        trial_value = trial.suggest_int(param, 1, 500)\n",
        "        row = input_row.copy()\n",
        "        row[param] = trial_value\n",
        "        df_input = pd.DataFrame([row])\n",
        "        pred = model.predict(df_input)[0]\n",
        "        return pred  # Maximizing Avg Speed\n",
        "\n",
        "    #optuna.logging.disable_default_handler()\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=1000)\n",
        "    print(f\"Max predicted avg speed: {study.best_value}\")\n",
        "\n",
        "    best_val = study.best_params[param]\n",
        "    optimized_params[param] = best_val\n",
        "\n",
        "    print(f\" Best {param}: {best_val}\")\n",
        "\n",
        "# Final output\n",
        "print(\"\\n All optimized parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "MnVIytdH9tnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Fixed track & weather settings — user-defined!\n",
        "fixed_conditions = {\n",
        "    \"Cornering\": 6,\n",
        "    \"Inclines\": 20,\n",
        "    \"Camber\": 44,\n",
        "    \"Grip\": 1,\n",
        "    \"Altitude\": 31,\n",
        "    \"Roughness\": 49,\n",
        "    \"Width\": 29,\n",
        "    \"Temperature\": 29,\n",
        "    \"Humidity\": 23,\n",
        "    \"Wind (Avg. Speed)\": 97,\n",
        "    \"Wind (Gusts)\": 49,\n",
        "    \"Air Density\": 70,\n",
        "    \"Air Pressure\": 98,\n",
        "}\n",
        "\n",
        "# Order of optimization and relevant features\n",
        "optimization_order = [\n",
        "    (\"Engine\", [\"Grip\", \"Altitude\", \"Humidity\", \"Air Density\", \"Temperature\", \"Air Pressure\", \"Inclines\"]),\n",
        "    (\"Differential\", [\"Cornering\", \"Width\", \"Inclines\", \"Grip\", \"Temperature\", \"Air Density\"]),\n",
        "    (\"Rear Wing\", [\"Air Pressure\", \"Air Density\", \"Cornering\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Roughness\"]),\n",
        "    (\"Brake Balance\", [\"Width\", \"Cornering\", \"Roughness\", \"Temperature\"]),\n",
        "    (\"Front Wing\", [\"Air Pressure\", \"Cornering\", \"Air Density\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Wind (Gusts)\"]),\n",
        "    (\"Suspension\", [\"Grip\", \"Inclines\", \"Cornering\", \"Camber\", \"Width\", \"Roughness\"]),\n",
        "]\n",
        "\n",
        "# Storage for optimized parameters\n",
        "optimized_params = {}\n",
        "\n",
        "# Optimization loop\n",
        "for param, relevant_features in optimization_order:\n",
        "    print(f\"\\n Optimizing {param}...\")\n",
        "\n",
        "    # Features for model = track/weather + already optimized (excluding the current param)\n",
        "    model_features = [f for f in relevant_features if f not in optimized_params] + [param]\n",
        "    model_df = df[model_features + [\"Avg Speed\"]].dropna()\n",
        "\n",
        "    X = model_df[model_features]\n",
        "    y = model_df[\"Avg Speed\"]\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Prepare fixed input for this stage, excluding already optimized parameters\n",
        "    input_row = {f: fixed_conditions[f] for f in relevant_features if f not in optimized_params}\n",
        "    input_row.update(optimized_params)  # Include already optimized parameters\n",
        "\n",
        "    def objective(trial):\n",
        "        trial_value = trial.suggest_int(param, 1, 500)\n",
        "        row = input_row.copy()\n",
        "        row[param] = trial_value\n",
        "        df_input = pd.DataFrame([row])\n",
        "\n",
        "        # Ensure that the input data has the same columns as the model features (including the current param)\n",
        "        pred = model.predict(df_input[model_features])[0]\n",
        "        return pred  # Maximizing Avg Speed\n",
        "\n",
        "    optuna.logging.disable_default_handler()\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "    print(f\"Max predicted avg speed: {study.best_value}\")\n",
        "\n",
        "    best_val = study.best_params[param]\n",
        "    optimized_params[param] = best_val\n",
        "\n",
        "    print(f\" Best {param}: {best_val}\")\n",
        "\n",
        "# Final output\n",
        "print(\"\\n All optimized parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "8B42zq-cEWfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Fixed track & weather settings — user-defined!\n",
        "fixed_conditions = {\n",
        "    \"Cornering\": 6,\n",
        "    \"Inclines\": 20,\n",
        "    \"Camber\": 44,\n",
        "    \"Grip\": 1,\n",
        "    \"Altitude\": 31,\n",
        "    \"Roughness\": 49,\n",
        "    \"Width\": 29,\n",
        "    \"Temperature\": 29,\n",
        "    \"Humidity\": 23,\n",
        "    \"Wind (Avg. Speed)\": 97,\n",
        "    \"Wind (Gusts)\": 49,\n",
        "    \"Air Density\": 70,\n",
        "    \"Air Pressure\": 98,\n",
        "}\n",
        "\n",
        "# Dictionary to store optimized values\n",
        "optimized_params = {}\n",
        "\n",
        "def optimize_stage(param_names, relevant_features, dependency_keys=[]):\n",
        "    \"\"\"\n",
        "    param_names: list of parameter names to optimize (even if only one)\n",
        "    relevant_features: list (or set) of fixed-condition features relevant to the model\n",
        "    dependency_keys: list of keys from optimized_params that must be included in the model input\n",
        "    \"\"\"\n",
        "    # Build the model features.\n",
        "    # Ensure a consistent order: first the fixed features, then dependency keys, then the parameters to optimize.\n",
        "    model_features = list(relevant_features) + dependency_keys + param_names\n",
        "\n",
        "    # Create a DataFrame for training.\n",
        "    model_df = df[model_features + [\"Avg Speed\"]].dropna()\n",
        "    X = model_df[model_features]\n",
        "    y = model_df[\"Avg Speed\"]\n",
        "\n",
        "    # Train the model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Prepare fixed input row from fixed_conditions (only for the relevant features)\n",
        "    input_row = {f: fixed_conditions[f] for f in relevant_features}\n",
        "    # Add dependency values (if any)\n",
        "    for key in dependency_keys:\n",
        "        input_row[key] = optimized_params[key]\n",
        "\n",
        "    # Define the objective for the trial\n",
        "    def objective(trial):\n",
        "        row = input_row.copy()\n",
        "        for param in param_names:\n",
        "            # Suggest values for each parameter; adjust the range as needed.\n",
        "            row[param] = trial.suggest_int(param, 1, 500)\n",
        "        # Force the column order to match model_features\n",
        "        df_input = pd.DataFrame([row], columns=model_features)\n",
        "        pred = model.predict(df_input)[0]\n",
        "        return pred  # We are maximizing Avg Speed\n",
        "\n",
        "    optuna.logging.disable_default_handler()\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "\n",
        "    # Save optimized values for all parameters in this stage\n",
        "    best_values = study.best_params\n",
        "    for param in param_names:\n",
        "        optimized_params[param] = best_values[param]\n",
        "        print(f\"Optimized {param}: {best_values[param]} (Max predicted avg speed: {study.best_value})\")\n",
        "\n",
        "# 1. Optimize Engine (independent)\n",
        "engine_features = [\"Grip\", \"Altitude\", \"Humidity\", \"Air Density\", \"Temperature\", \"Air Pressure\", \"Inclines\"]\n",
        "optimize_stage(param_names=[\"Engine\"], relevant_features=engine_features, dependency_keys=[])\n",
        "\n",
        "# 2. Optimize Differential (depends on Engine)\n",
        "differential_features = [\"Cornering\", \"Width\", \"Inclines\", \"Grip\", \"Temperature\", \"Air Density\"]\n",
        "optimize_stage(param_names=[\"Differential\"], relevant_features=differential_features, dependency_keys=[\"Engine\"])\n",
        "\n",
        "# 3. Optimize Rear Wing and Front Wing together (do NOT depend on any previously optimized values)\n",
        "rear_wing_features = {\"Air Pressure\", \"Air Density\", \"Cornering\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Roughness\"}\n",
        "front_wing_features = {\"Air Pressure\", \"Cornering\", \"Air Density\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Wind (Gusts)\"}\n",
        "wing_features = list(rear_wing_features.union(front_wing_features))\n",
        "optimize_stage(param_names=[\"Rear Wing\", \"Front Wing\"], relevant_features=wing_features, dependency_keys=[])\n",
        "\n",
        "# 4. Optimize Brake Balance (depends on Differential only)\n",
        "brake_balance_features = [\"Width\", \"Cornering\", \"Roughness\", \"Temperature\"]\n",
        "optimize_stage(param_names=[\"Brake Balance\"], relevant_features=brake_balance_features, dependency_keys=[\"Differential\"])\n",
        "\n",
        "# 5. Optimize Suspension (independent)\n",
        "suspension_features = [\"Grip\", \"Inclines\", \"Cornering\", \"Camber\", \"Width\", \"Roughness\"]\n",
        "optimize_stage(param_names=[\"Suspension\"], relevant_features=suspension_features, dependency_keys=[])\n",
        "\n",
        "# Final output\n",
        "print(\"\\nAll optimized parameters:\")\n",
        "for key, value in optimized_params.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "id": "XhY3tD-2KxCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load your CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"simulator_data.csv\")  # replace with your file path\n",
        "\n",
        "# Step 2: Calculate the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Step 3: Plot the correlation matrix\n",
        "plt.figure(figsize=(20, 20))  # adjust size as needed\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True, vmin=-0.05, vmax=0.05)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p2M4Y2nX41BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Define the tire parameters and their lap time formulas\n",
        "def lap_time_super_soft(X):\n",
        "    return (69.269-0.133470588) + 0.133470588 * X\n",
        "\n",
        "def lap_time_soft(X):\n",
        "    return 70.53 + 0.066774194 * X\n",
        "\n",
        "def lap_time_medium(X):\n",
        "    return 70.927 + 0.0652222222222222 * X\n",
        "\n",
        "def lap_time_hard(X):\n",
        "    return 70.257 + 0.107 * X\n",
        "\n",
        "# Tire data with their lifespan\n",
        "tire_lifespan = {\n",
        "    \"super_soft\": 17,\n",
        "    \"soft\": 31,\n",
        "    \"medium\": 36,\n",
        "    \"hard\": 42\n",
        "}\n",
        "\n",
        "# Pit stop penalty\n",
        "pit_stop_time = 30  # seconds\n",
        "\n",
        "# Function to calculate the total race time for a given strategy\n",
        "def calculate_race_time(laps, strategy):\n",
        "    total_time = 0\n",
        "    total_pit_stops = 0\n",
        "    lap_index = 0\n",
        "    lap_counter = 0\n",
        "\n",
        "    while lap_counter < laps:\n",
        "        tire, stint_laps = strategy[lap_index]\n",
        "\n",
        "        # Ensure we don't exceed the total laps\n",
        "        if lap_counter + stint_laps > laps:\n",
        "            stint_laps = laps - lap_counter\n",
        "\n",
        "        # Calculate the lap times for this stint\n",
        "        lap_times = []\n",
        "        for i in range(stint_laps):\n",
        "            if tire == \"super_soft\":\n",
        "                lap_times.append(lap_time_super_soft(i + 1))\n",
        "            elif tire == \"soft\":\n",
        "                lap_times.append(lap_time_soft(i + 1))\n",
        "            elif tire == \"medium\":\n",
        "                lap_times.append(lap_time_medium(i + 1))\n",
        "            elif tire == \"hard\":\n",
        "                lap_times.append(lap_time_hard(i + 1))\n",
        "\n",
        "        total_time += sum(lap_times)  # Add the lap times of this stint\n",
        "        lap_counter += stint_laps\n",
        "\n",
        "        # If we are not at the last stint, account for a pit stop\n",
        "        if lap_counter < laps:\n",
        "            total_time += pit_stop_time  # Pit stop penalty\n",
        "            total_pit_stops += 1\n",
        "\n",
        "        lap_index += 1\n",
        "        if lap_index >= len(strategy):\n",
        "            break\n",
        "\n",
        "    return total_time\n",
        "\n",
        "# Function to generate possible strategies dynamically\n",
        "def generate_strategies(laps):\n",
        "    strategies = []\n",
        "    tire_choices = [\"super_soft\", \"soft\", \"medium\", \"hard\"]\n",
        "\n",
        "    # Generate strategies by breaking the laps into multiple stints\n",
        "    for tire1 in tire_choices:\n",
        "        for tire2 in tire_choices:\n",
        "            for tire3 in tire_choices:\n",
        "                for tire4 in tire_choices:\n",
        "                  for tire5 in tire_choices:\n",
        "                    strategy = []\n",
        "                    remaining_laps = laps\n",
        "\n",
        "                    # Create dynamic stints for each tire\n",
        "                    for tire in [tire1, tire2, tire3, tire4, tire5]:\n",
        "                    #for tire in [tire1, tire2, tire3, tire4]:\n",
        "                    #for tire in [tire1, tire2, tire3]:\n",
        "                    #for tire in [tire1, tire2]:\n",
        "                        stint_laps = tire_lifespan[tire]\n",
        "\n",
        "                        if remaining_laps > stint_laps:\n",
        "                            strategy.append((tire, stint_laps))\n",
        "                            remaining_laps -= stint_laps\n",
        "                        else:\n",
        "                            strategy.append((tire, remaining_laps))\n",
        "                            break\n",
        "\n",
        "                    if sum([stint[1] for stint in strategy]) == laps:\n",
        "                        strategies.append(strategy)\n",
        "\n",
        "    return strategies\n",
        "\n",
        "# Function to find the best strategy\n",
        "def optimize_strategy(laps):\n",
        "    best_time = math.inf\n",
        "    best_strategy = None\n",
        "\n",
        "    strategies = generate_strategies(laps)\n",
        "\n",
        "    for strategy in strategies:\n",
        "        total_time = calculate_race_time(laps, strategy)\n",
        "        if total_time < best_time:\n",
        "            best_time = total_time\n",
        "            best_strategy = strategy\n",
        "\n",
        "    return best_strategy, best_time\n",
        "\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    race_laps = 83\n",
        "    best_strategy, best_time = optimize_strategy(race_laps)\n",
        "    print(f\"Best Strategy: {best_strategy}\")\n",
        "    print(f\"Best Total Time: {best_time} seconds\")\n"
      ],
      "metadata": {
        "id": "VQEz50zWfvhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best Strategy: [('super_soft', 17), ('super_soft', 17), ('super_soft', 17), ('super_soft', 17), ('super_soft', 15)]\n",
        "Best Total Time: 5967.027470416 seconds\n",
        "Best Strategy: [('super_soft', 17), ('super_soft', 17), ('soft', 31), ('soft', 18)]\n",
        "Best Total Time: 5986.496387326 seconds"
      ],
      "metadata": {
        "id": "jMfNBV63wjmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1LiOt7yQL5T"
      },
      "source": [
        "## **Analytics for Race 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZcWkDUrQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZneIB62QL5T"
      },
      "source": [
        "## **Analytics for Race 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdHKUysbQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFETMTcZQL5T"
      },
      "source": [
        "## **Analytics for Race 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS0Om6gBQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ajs8np_QL5T"
      },
      "source": [
        "## **Analytics for Race 5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfLSArfnQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFvVYCufQL5T"
      },
      "source": [
        "## **Debrief Race Calendar before Final Race**\n",
        "\n",
        "*Write a longer text (200-500 words) reflecting on what were the main ideas you started the seminar with, how you improved your models to achieve better performance and what strategy and analytics you want to use for your final race during seminar day*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1t67p2kQL5T"
      },
      "source": [
        "## **Analytics for Final Race**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVrrOFguQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kulv8cpKcq9_"
      },
      "source": [
        "## **References**\n",
        "- Cite all references you need according to chair guidelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OLrMDxWc8oM"
      },
      "source": [
        "Liu, Xuan; Shi, Savannah Wei; Teixeira, Thales; Wedel, Michel (2018): Video Content Marketing: The Making of Clips, Journal of Marketing, Vol. 82, 86-101."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}