{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannesKock/RaceTeam2_CHP/blob/main/Race_Team_Project_Notebook25.04.V2_CS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycXWv5-jYpIC"
      },
      "source": [
        "# **Race Team Project Notebook**\n",
        "Names:\n",
        "\n",
        "Matr.:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUOq9_tORt3e"
      },
      "source": [
        "Please write down the Name of the Group member you worked on each section of code. This is necessary for grading by Studienbüro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8aiLYHdaX9P"
      },
      "source": [
        "# **Analytics for Race 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuIPnDlucl2q"
      },
      "source": [
        "- For each race day built one section with the code that you built for this race\n",
        "- If you keep the same code during the next races copy the code over to the next section\n",
        "- Describe why you built your analytics the way you do and interprete after each race what went well and what you want to improve on\n",
        "- During motivation and interpretation try to cite online sources that you read to make better decisions (e.g., scientific articles on machine learning, blog posts, github pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhtO3nrmQL5S"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Paula, Cedric, Hannes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we read the CSV file\"simulator_data.csv\" into a pandas DataFrame for analysis. We displays the first few rows, lists the column names, provides summary statistics, and shows a concise overview of the dataset's structure.\n"
      ],
      "metadata": {
        "id": "1eAN599PnjCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading Data and summarizing contens\n",
        "#https://www.datacamp.com/tutorial/pandas-read-csv\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "print(df.describe())\n",
        "print(df.info())\n"
      ],
      "metadata": {
        "id": "rQ78TqIW1vi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see what the Data looks like we create scatter plots showing the relationship between each parameter in the dataset and lap time."
      ],
      "metadata": {
        "id": "MBL5sfS2n9Q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots (Parameter vs. Lap Time)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "param_cols = df.columns.drop(\"Lap Time\")\n",
        "\n",
        "for col in param_cols:\n",
        "    plt.figure()\n",
        "    sns.scatterplot(x=df[col], y=df[\"Lap Time\"], alpha=0.3)\n",
        "    plt.title(f\"{col} vs. Lap Time\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "L1t83oN149ZJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We noticed that the Laps within the \"Simulator_Data.csv\" have different lengths, therefore we divide \"Lap Distance\" by \"Lap_time\" and multiply by 3600 to get \"Avg. Speed\" in km/h.\n",
        "\n",
        "Then we again generate scatter plots to visualize the relationship between each parameter (excluding \"Lap Time\" and \"Avg. Speed\") and the calculated average speed."
      ],
      "metadata": {
        "id": "Zsu4G1XLoMDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots (Parameter vs. Avg. Speed)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Durchschnittsgeschwindigkeit berechnen (falls noch nicht vorhanden)\n",
        "if \"Avg. Speed\" not in df.columns:\n",
        "    df[\"Avg. Speed\"] = df[\"Lap Distance\"] / (df[\"Lap Time\"] / 3600)\n",
        "\n",
        "# Alle Spalten außer \"Lap Time\" und \"Avg. Speed\" verwenden\n",
        "param_cols = df.columns.drop([\"Lap Time\", \"Avg. Speed\"])\n",
        "\n",
        "# Scatterplots erzeugen\n",
        "for col in param_cols:\n",
        "    plt.figure()\n",
        "    sns.scatterplot(x=df[col], y=df[\"Avg. Speed\"], alpha=0.3)\n",
        "    plt.title(f\"{col} vs. Avg. Speed\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Avg. Speed (km/h)\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "83ZAwsoP_YTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the scatter plots did not lead to much insights, we wanted to se how the different parameters correlate with each other. We hoped to be able to use logic to figure out how to set the car paramters.\n",
        "\n",
        "We calculated the correlation matrix to explore how the variables relate to each other. The correlations are visualized using a heatmap to easily identify weak or strong linear relationships between parameters."
      ],
      "metadata": {
        "id": "cmwkBmr2q5CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load your CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"simulator_data.csv\")  # replace with your file path\n",
        "\n",
        "# Step 2: Calculate the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Step 3: Plot the correlation matrix\n",
        "plt.figure(figsize=(20, 20))  # adjust size as needed\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True, vmin=-0.05, vmax=0.05)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p2M4Y2nX41BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next four code blocks are first trys at using ML Models to predict and further understand the Parameters.\n",
        "\n",
        "These attempts did not lead to much, they are still in here because they are an important step on the way to our Final Solution for this weeks race analytics.\n",
        "\n",
        "The four Codes are:\n",
        "1. first try to use a randomForrest Model and optuna to find best car parameters\n",
        "2. To further understand the model parameters, we used a ML Model to create a SHAP-Diagram\n",
        "3. Using the Model from the SHAP-Diagram, we try to find optimal Carparameters using optuna\n",
        "4. to improve the ML Model-Parameters, we do a Grid-Search which took forever and did not lead to noticably better results."
      ],
      "metadata": {
        "id": "HPCv-8V_r0yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import optuna\n",
        "\n",
        "# === 1. Daten einlesen ===\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Ziel- und Feature-Spalten\n",
        "target_col = \"Lap Time\"\n",
        "feature_cols = df.columns.drop(target_col)\n",
        "\n",
        "# === 2. Modell trainieren ===\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "# Optional: Skalieren\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Training/Test-Split (z. B. für Validierung)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === 3. Bayesian Optimization Setup (Optuna) ===\n",
        "\n",
        "# Gegeben: Umgebungsbedingungen\n",
        "fixed_conditions = {\n",
        "    'Lap Distance': 3.7,\n",
        "    'Cornering': 6,\n",
        "    'Inclines': 20,\n",
        "    'Camber': 44,\n",
        "    'Grip': 1,\n",
        "    'Wind (Avg. Speed)': 97,\n",
        "    'Temperature': 29,\n",
        "    'Humidity': 23,\n",
        "    'Air Density': 70,\n",
        "    'Air Pressure': 98,\n",
        "    'Wind (Gusts)': 49,\n",
        "    'Altitude': 31,\n",
        "    'Roughness': 49,\n",
        "    'Width': 29\n",
        "}\n",
        "\n",
        "def objective(trial):\n",
        "    # Optimierbare Fahrzeugparameter\n",
        "    params = {\n",
        "        'Rear Wing': trial.suggest_float('Rear Wing', 0.0, 500),\n",
        "        'Engine': trial.suggest_float('Engine', 0.0, 500),\n",
        "        'Front Wing': trial.suggest_float('Front Wing', 0.0, 500),\n",
        "        'Brake Balance': trial.suggest_float('Brake Balance', 0.0, 500),\n",
        "        'Differential': trial.suggest_float('Differential', 0.0, 500),\n",
        "        'Suspension': trial.suggest_float('Suspension', 0.0, 500),\n",
        "    }\n",
        "\n",
        "    # Kombinieren mit festen Bedingungen\n",
        "    full_input = {**fixed_conditions, **params}\n",
        "    X_input = pd.DataFrame([full_input])\n",
        "    X_input_scaled = scaler.transform(X_input)\n",
        "\n",
        "    # Vorhersage durch Modell\n",
        "    lap_time = model.predict(X_input_scaled)[0]\n",
        "    return lap_time\n",
        "\n",
        "# Optuna-Studie starten\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Ergebnisse\n",
        "print(\"Beste Parameterkombination:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n",
        "print(f\"Erwartete Rundenzeit: {study.best_value:.4f} Sekunden\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "a9HOY9CO106A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy  as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Falls noch nicht geschehen: Durchschnittsgeschwindigkeit berechnen\n",
        "if \"Avg. Speed\" not in df.columns:\n",
        "    df[\"Avg. Speed\"] = df[\"Lap Distance\"] / (df[\"Lap Time\"] / 3600)\n",
        "\n",
        "# 2. Features & Ziel definieren\n",
        "feature_cols = [\n",
        "    'Lap Distance', 'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width',\n",
        "    'Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential',\n",
        "    'Suspension'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"Avg. Speed\"]\n",
        "\n",
        "# 3. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# 4. Modell trainieren (XGBoost)\n",
        "#model = xgb.XGBRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "model = xgb.XGBRegressor(colsample_bytree=1.0, learning_rate = 0.05, max_depth = 6, min_child_weight = 1, n_estimators = 300, subsample = 0.8)\n",
        "model.fit(X_train, y_train)\n",
        "y_hat = model.predict(X_test)\n",
        "error = np.mean(np.abs(y_test - y_hat))\n",
        "print(error)\n",
        "\n",
        "# # 5. SHAP-Werte berechnen\n",
        "explainer = shap.Explainer(model)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# # 6. SHAP Summary Plot\n",
        "shap.summary_plot(shap_values, X_test)\n"
      ],
      "metadata": {
        "id": "_4C7T1BhGyGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# You can get this from df.mean().values or pick a sample row\n",
        "base_input = df[feature_cols].mean().values\n",
        "\n",
        "for fc in fixed_conditions:\n",
        "    base_input[feature_cols.index(fc)] = fixed_conditions[fc]\n",
        "\n",
        "# Indices of the features we want to optimize\n",
        "optim_features = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "optim_indices = [feature_cols.index(f) for f in optim_features]\n",
        "\n",
        "# Define bounds from your dataset (here we use min/max)\n",
        "feature_bounds = {\n",
        "    'Rear Wing': (1, 500),\n",
        "    'Engine': (1, 500),\n",
        "    'Front Wing': (1, 500),\n",
        "    'Brake Balance': (1, 500),\n",
        "    'Differential': (1, 500),\n",
        "    'Suspension': (1, 500),\n",
        "}\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    x = base_input.copy()\n",
        "\n",
        "    for f in optim_features:\n",
        "        val = trial.suggest_int(f, int(feature_bounds[f][0]), int(feature_bounds[f][1]))\n",
        "        x[feature_cols.index(f)] = val\n",
        "\n",
        "    pred = model.predict(np.array([x]))[0]\n",
        "    return pred  # Optuna will maximize if we tell it to\n",
        "\n",
        "# Run Optuna study\n",
        "optuna.logging.disable_default_handler()\n",
        "study = optuna.create_study(direction='maximize')  # use 'minimize' if lower lap time is better\n",
        "study.optimize(objective, n_trials=255)\n",
        "\n",
        "\n",
        "# Show results\n",
        "print(\"Best params:\")\n",
        "for k, v in study.best_params.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "print(f\"Max predicted avg speed: {study.best_value}\")\n"
      ],
      "metadata": {
        "id": "6v_W-wPAUbrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grid Search for best Model Parameters\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Create the target variable: average speed\n",
        "df['Avg Speed'] = df['Lap Distance'] / df['Lap Time']\n",
        "\n",
        "# Drop unused columns\n",
        "X = df.drop(columns=['Lap Distance', 'Lap Time', 'Avg Speed'])\n",
        "y = df['Avg Speed']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define XGBoost Regressor\n",
        "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Define grid search parameters\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [100, 300],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'min_child_weight': [1, 5]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "jJHJ_frRk-Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determining, which Parameters have the biggest impacts on Lap Times / Speeds.\n",
        "\n",
        "\n",
        "\n",
        "This code trains an XGBoost Regressor model to predict the average speed of a car based on various track and environmental features. First, it loads the data and calculates the average speed by dividing the lap distance by the lap time. The code then preprocesses the data by removing unnecessary columns and splits it into training and testing sets. After training the model, it evaluates the feature importances to determine which variables most strongly influence the predicted average speed. **Finally, it plots a bar chart to visually display the feature importances, providing insights into the relative impact of each feature.**"
      ],
      "metadata": {
        "id": "CL-Q4Cb9qo6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = df[\"Lap Distance\"] / df[\"Lap Time\"]\n",
        "\n",
        "X = df.drop(columns=[\"Lap Distance\", \"Lap Time\", \"Avg Speed\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = XGBRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Plot feature importance\n",
        "importances = model.feature_importances_\n",
        "feat_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "feat_importance.plot(kind=\"bar\", figsize=(12, 6), title=\"Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Lgr-Ysmx0tl9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determining, which Track/Weather Parameters have the biggest impacts on each car parameter\n",
        "\n",
        "This code performs feature importance analysis for various car setup parameters based on environmental and track/weather conditions. It uses the XGBoost Regressor to model the relationship between the track/weather variables and each car setup parameter. The data is split into training and test sets, and the model is evaluated using the R² score to measure prediction accuracy. After training, the code extracts and plots the feature importances for each car parameter, helping to identify which track/weather variables have the most significant impact on each car setup."
      ],
      "metadata": {
        "id": "jhlF9wcwouWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Define inputs (track/weather features) and targets (car parameters)\n",
        "track_weather_features = [\n",
        "    'Lap Distance', 'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width'\n",
        "]\n",
        "\n",
        "car_setup_params = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "\n",
        "# Store feature importances for each car parameter\n",
        "feature_importance_dict = {}\n",
        "\n",
        "# Loop through car parameters\n",
        "for param in car_setup_params:\n",
        "    X = df[track_weather_features]\n",
        "    y = df[param]\n",
        "\n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate R² score\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n{param} - R²: {score:.3f}\")\n",
        "\n",
        "    # Get feature importances and filter by importance > 0.1\n",
        "    importances = model.feature_importances_\n",
        "    importance_series = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Store importances\n",
        "    feature_importance_dict[param] = importance_series\n",
        "\n",
        "    # Display the features with importance > 0.1\n",
        "    print(f\"\\nFor {param}, track/weather parameters with importance > 0.1:\")\n",
        "    for feature, importance in importance_series.items():\n",
        "        if importance > 0.075:\n",
        "            print(f\" - {feature}: {importance:.3f}\")\n",
        "\n",
        "    # Optional: Plot feature importances\n",
        "    importance_series.plot(kind='barh', title=f\"Feature Importance for {param}\", figsize=(8, 5))\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "piDIG5ojfAUz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basiclly the same as the code before, but the other car parameters are also included in the models to determine the parameter importance\n",
        "#This is done to see, how different car parameters might influence each other\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Define inputs (track/weather features) and targets (car parameters)\n",
        "track_weather_features = [\n",
        "    'Lap Distance', 'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width'\n",
        "]\n",
        "\n",
        "car_setup_params = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "\n",
        "# Store feature importances for each car parameter\n",
        "feature_importance_dict = {}\n",
        "\n",
        "# Loop through car parameters\n",
        "for param in car_setup_params:\n",
        "    # Include track/weather features and other car parameters (excluding the target parameter itself)\n",
        "    other_car_params = [p for p in car_setup_params if p != param]\n",
        "    X = df[track_weather_features + other_car_params]\n",
        "    y = df[param]\n",
        "\n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate R² score\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n{param} - R²: {score:.3f}\")\n",
        "\n",
        "    # Get feature importances and sort them\n",
        "    importances = model.feature_importances_\n",
        "    importance_series = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Store importances\n",
        "    feature_importance_dict[param] = importance_series\n",
        "\n",
        "    # Display the features with importance > 0.075\n",
        "    print(f\"\\nFor {param}, all parameters with importance > 0.075:\")\n",
        "    for feature, importance in importance_series.items():\n",
        "        if importance > 0.075:\n",
        "            print(f\" - {feature}: {importance:.3f}\")\n",
        "\n",
        "    # Optional: Plot feature importances\n",
        "    importance_series.plot(kind='barh', title=f\"Feature Importance for {param}\", figsize=(8, 5))\n",
        "    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "D3kuj_jRFkln",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FR-MJQxykiEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential optimization of car-parameters.\n",
        "\n",
        "We optimize each Car-parameter in a predefined order, ensuring that each optimization builds upon the previous ones. (Order: Feature Importance (highest to lowest)(see above))\n",
        "\n",
        "For each car parameter, we first train a predictive model for average speed using relevant track/weather variables and already optimized parameters. Then, using Optuna, we search for the optimal value of the current car parameter that maximizes the predicted average speed.\n",
        "\n",
        "What track and wheather parameters are important for each Car-Parameter was determined before (see above)\n",
        "\n",
        "Order of optimization and relevant track/weather parameters:\n",
        "\n",
        "1. Engine: Grip, Altitude, Humidity, Air Density, Temperature, Air Pressure, Inclines\n",
        "2. Differetial: Cornering, Width, Inclines, Grip, Temprature, Air Density\n",
        "3. Rear Wing: Air Pressure, Air Density, Cornering, Inclines, Wind (Avg. Speed), Humidity, Roughness\n",
        "4. Break Balance: Width, Cornering, Roughness, Temperature\n",
        "5. Front Wing: Air Pressure, Cornering, Air Density, Inclines, Wind (Avg. Speed), Humidity, Wind (Gusts)\n",
        "6. Suspension: Grip, Inclines, Cornering, Camber, Width, Roughness\n"
      ],
      "metadata": {
        "id": "1HSUU_WOlmll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Fixed track & weather settings — user-defined!\n",
        "fixed_conditions = {\n",
        "    \"Cornering\": 6,\n",
        "    \"Inclines\": 20,\n",
        "    \"Camber\": 44,\n",
        "    \"Grip\": 1,\n",
        "    \"Altitude\": 31,\n",
        "    \"Roughness\": 49,\n",
        "    \"Width\": 29,\n",
        "    \"Temperature\": 29,\n",
        "    \"Humidity\": 23,\n",
        "    \"Wind (Avg. Speed)\": 97,\n",
        "    \"Wind (Gusts)\": 49,\n",
        "    \"Air Density\": 70,\n",
        "    \"Air Pressure\": 98,\n",
        "}\n",
        "\n",
        "# Order of optimization and relevant features\n",
        "optimization_order = [\n",
        "    (\"Engine\", [\"Grip\", \"Altitude\", \"Humidity\", \"Air Density\", \"Temperature\", \"Air Pressure\", \"Inclines\"]),\n",
        "    (\"Differential\", [\"Cornering\", \"Width\", \"Inclines\", \"Grip\", \"Temperature\", \"Air Density\"]),\n",
        "    (\"Rear Wing\", [\"Air Pressure\", \"Air Density\", \"Cornering\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Roughness\"]),\n",
        "    (\"Brake Balance\", [\"Width\", \"Cornering\", \"Roughness\", \"Temperature\"]),\n",
        "    (\"Front Wing\", [\"Air Pressure\", \"Cornering\", \"Air Density\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Wind (Gusts)\"]),\n",
        "    (\"Suspension\", [\"Grip\", \"Inclines\", \"Cornering\", \"Camber\", \"Width\", \"Roughness\"]),\n",
        "]\n",
        "\n",
        "# Storage for optimized parameters\n",
        "optimized_params = {}\n",
        "\n",
        "\n",
        "# Optimization loop\n",
        "for param, relevant_features in optimization_order:\n",
        "    print(f\"\\n Optimizing {param}...\")\n",
        "\n",
        "    # Features for model = track/weather + already optimized + current param\n",
        "    model_features = relevant_features + list(optimized_params.keys()) + [param]\n",
        "    model_df = df[model_features + [\"Avg Speed\"]].dropna()\n",
        "\n",
        "    X = model_df[model_features]\n",
        "    y = model_df[\"Avg Speed\"]\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Prepare fixed input for this stage\n",
        "    input_row = {f: fixed_conditions[f] for f in relevant_features}\n",
        "    input_row.update(optimized_params)  # Include already optimized parameters\n",
        "\n",
        "    def objective(trial):\n",
        "        trial_value = trial.suggest_int(param, 1, 500)\n",
        "        row = input_row.copy()\n",
        "        row[param] = trial_value\n",
        "        df_input = pd.DataFrame([row])\n",
        "        pred = model.predict(df_input)[0]\n",
        "        return pred  # Maximizing Avg Speed\n",
        "\n",
        "    optuna.logging.disable_default_handler()\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=10)\n",
        "    print(f\"Max predicted avg speed: {study.best_value}\")\n",
        "\n",
        "    best_val = study.best_params[param]\n",
        "    optimized_params[param] = best_val\n",
        "\n",
        "    print(f\" Best {param}: {best_val}\")\n",
        "\n",
        "# Final output\n",
        "print(\"\\n All optimized parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "Lu2xXtIKRJMF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "All optimized parameters:\n",
        "Engine: 30\n",
        "Differential: 1\n",
        "Rear Wing: 48\n",
        "Brake Balance: 3\n",
        "Front Wing: 37\n",
        "Suspension: 124"
      ],
      "metadata": {
        "id": "-U8GQaEz_Gao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Same code as above, but the optimization order of the Car-Parameters is flipped.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Fixed track & weather settings — user-defined!\n",
        "fixed_conditions = {\n",
        "    \"Cornering\": 6,\n",
        "    \"Inclines\": 20,\n",
        "    \"Camber\": 44,\n",
        "    \"Grip\": 1,\n",
        "    \"Altitude\": 31,\n",
        "    \"Roughness\": 49,\n",
        "    \"Width\": 29,\n",
        "    \"Temperature\": 29,\n",
        "    \"Humidity\": 23,\n",
        "    \"Wind (Avg. Speed)\": 97,\n",
        "    \"Wind (Gusts)\": 49,\n",
        "    \"Air Density\": 70,\n",
        "    \"Air Pressure\": 98,\n",
        "}\n",
        "\n",
        "# Order of optimization and relevant features\n",
        "optimization_order = [\n",
        "    (\"Suspension\", [\"Grip\", \"Inclines\", \"Cornering\", \"Camber\", \"Width\", \"Roughness\"]),\n",
        "    (\"Front Wing\", [\"Air Pressure\", \"Cornering\", \"Air Density\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Wind (Gusts)\"]),\n",
        "    (\"Brake Balance\", [\"Width\", \"Cornering\", \"Roughness\", \"Temperature\"]),\n",
        "    (\"Rear Wing\", [\"Air Pressure\", \"Air Density\", \"Cornering\", \"Inclines\", \"Wind (Avg. Speed)\", \"Humidity\", \"Roughness\"]),\n",
        "    (\"Differential\", [\"Cornering\", \"Width\", \"Inclines\", \"Grip\", \"Temperature\", \"Air Density\"]),\n",
        "    (\"Engine\", [\"Grip\", \"Altitude\", \"Humidity\", \"Air Density\", \"Temperature\", \"Air Pressure\", \"Inclines\"])\n",
        "]\n",
        "\n",
        "# Storage for optimized parameters\n",
        "optimized_params = {}\n",
        "\n",
        "\n",
        "# Optimization loop\n",
        "for param, relevant_features in optimization_order:\n",
        "    print(f\"\\n Optimizing {param}...\")\n",
        "\n",
        "    # Features for model = track/weather + already optimized + current param\n",
        "    model_features = relevant_features + list(optimized_params.keys()) + [param]\n",
        "    model_df = df[model_features + [\"Avg Speed\"]].dropna()\n",
        "\n",
        "    X = model_df[model_features]\n",
        "    y = model_df[\"Avg Speed\"]\n",
        "\n",
        "    # Train model\n",
        "    model = XGBRegressor(random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Prepare fixed input for this stage\n",
        "    input_row = {f: fixed_conditions[f] for f in relevant_features}\n",
        "    input_row.update(optimized_params)  # Include already optimized parameters\n",
        "\n",
        "    def objective(trial):\n",
        "        trial_value = trial.suggest_int(param, 1, 500)\n",
        "        row = input_row.copy()\n",
        "        row[param] = trial_value\n",
        "        df_input = pd.DataFrame([row])\n",
        "        pred = model.predict(df_input)[0]\n",
        "        return pred  # Maximizing Avg Speed\n",
        "\n",
        "    #optuna.logging.disable_default_handler()\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=1000)\n",
        "    print(f\"Max predicted avg speed: {study.best_value}\")\n",
        "\n",
        "    best_val = study.best_params[param]\n",
        "    optimized_params[param] = best_val\n",
        "\n",
        "    print(f\" Best {param}: {best_val}\")\n",
        "\n",
        "# Final output\n",
        "print(\"\\n All optimized parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "MnVIytdH9tnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Race Strategy"
      ],
      "metadata": {
        "id": "br4U1GyguFO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Define the tire parameters and their lap time formulas\n",
        "def lap_time_super_soft(X):\n",
        "    return (69.269-0.141812499999999) + 0.141812499999999 * X\n",
        "\n",
        "def lap_time_soft(X):\n",
        "    return (70.53-0.0667741935483869) + 0.0667741935483869 * X\n",
        "\n",
        "def lap_time_medium(X):\n",
        "    return (70.927-0.0670857142857143) + 0.0670857142857143 * X\n",
        "\n",
        "def lap_time_hard(X):\n",
        "    return (70.257-0.109609756097561) + 0.109609756097561 * X\n",
        "\n",
        "# Tire data with their lifespan\n",
        "tire_lifespan = {\n",
        "    \"super_soft\": 16,\n",
        "    \"soft\": 30,\n",
        "    \"medium\": 35,\n",
        "    \"hard\": 41\n",
        "}\n",
        "\n",
        "# Pit stop penalty\n",
        "pit_stop_time = 30  # seconds\n",
        "\n",
        "# Function to calculate the total race time for a given strategy\n",
        "def calculate_race_time(laps, strategy):\n",
        "    total_time = 0\n",
        "    total_pit_stops = 0\n",
        "    lap_index = 0\n",
        "    lap_counter = 0\n",
        "\n",
        "    while lap_counter < laps:\n",
        "        tire, stint_laps = strategy[lap_index]\n",
        "\n",
        "        # Ensure we don't exceed the total laps\n",
        "        if lap_counter + stint_laps > laps:\n",
        "            stint_laps = laps - lap_counter\n",
        "\n",
        "        # Calculate the lap times for this stint\n",
        "        lap_times = []\n",
        "        for i in range(stint_laps):\n",
        "            if tire == \"super_soft\":\n",
        "                lap_times.append(lap_time_super_soft(i + 1))\n",
        "            elif tire == \"soft\":\n",
        "                lap_times.append(lap_time_soft(i + 1))\n",
        "            elif tire == \"medium\":\n",
        "                lap_times.append(lap_time_medium(i + 1))\n",
        "            elif tire == \"hard\":\n",
        "                lap_times.append(lap_time_hard(i + 1))\n",
        "\n",
        "        total_time += sum(lap_times)  # Add the lap times of this stint\n",
        "        lap_counter += stint_laps\n",
        "\n",
        "        # If we are not at the last stint, account for a pit stop\n",
        "        if lap_counter < laps:\n",
        "            total_time += pit_stop_time  # Pit stop penalty\n",
        "            total_pit_stops += 1\n",
        "\n",
        "        lap_index += 1\n",
        "        if lap_index >= len(strategy):\n",
        "            break\n",
        "\n",
        "    return total_time, total_pit_stops\n",
        "\n",
        "# Function to generate possible strategies dynamically\n",
        "def generate_strategies(laps):\n",
        "    strategies = []\n",
        "    tire_choices = [\"super_soft\", \"soft\", \"medium\", \"hard\"]\n",
        "\n",
        "    # Generate strategies by breaking the laps into multiple stints\n",
        "    for tire1 in tire_choices:\n",
        "        for tire2 in tire_choices:\n",
        "            for tire3 in tire_choices:\n",
        "                #for tire4 in tire_choices:\n",
        "                  #for tire5 in tire_choices:\n",
        "                    strategy = []\n",
        "                    remaining_laps = laps\n",
        "\n",
        "                    # Create dynamic stints for each tire\n",
        "                    #for tire in [tire1, tire2, tire3, tire4, tire5]:\n",
        "                    #for tire in [tire1, tire2, tire3, tire4]:\n",
        "                    for tire in [tire1, tire2, tire3]:\n",
        "                    #for tire in [tire1, tire2]:\n",
        "                        stint_laps = tire_lifespan[tire]\n",
        "\n",
        "                        if remaining_laps > stint_laps:\n",
        "                            strategy.append((tire, stint_laps))\n",
        "                            remaining_laps -= stint_laps\n",
        "                        else:\n",
        "                            strategy.append((tire, remaining_laps))\n",
        "                            break\n",
        "\n",
        "                    if sum([stint[1] for stint in strategy]) == laps:\n",
        "                        strategies.append(strategy)\n",
        "\n",
        "    return strategies\n",
        "\n",
        "# Function to find the best strategy\n",
        "def optimize_strategy(laps):\n",
        "    best_time = math.inf\n",
        "    best_strategy = None\n",
        "\n",
        "    strategies = generate_strategies(laps)\n",
        "\n",
        "    for strategy in strategies:\n",
        "        total_time, pit_stops = calculate_race_time(laps, strategy)\n",
        "        if total_time < best_time:\n",
        "            best_time = total_time\n",
        "            best_strategy = strategy\n",
        "            best_pit_stops = pit_stops\n",
        "\n",
        "    return best_strategy, best_time, best_pit_stops\n",
        "\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    race_laps = 83\n",
        "    best_strategy, best_time, total_pit_stops = optimize_strategy(race_laps)\n",
        "    print(f\"Best Strategy: {best_strategy}\")\n",
        "    print(f\"Best Total Time: {best_time} seconds\")\n",
        "    print(f\"Total Pit Stops: {total_pit_stops}\")\n"
      ],
      "metadata": {
        "id": "VQEz50zWfvhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best Strategy: [('super_soft', 16), ('super_soft', 16), ('super_soft', 16), ('super_soft', 16), ('soft', 19)]\n",
        "Best Total Time: 5972.774387096774 seconds\n",
        "\n",
        "Best Strategy: [('super_soft', 16), ('super_soft', 16), ('soft', 30), ('soft', 21)]\n",
        "Best Total Time: 5980.742354838709 seconds\n",
        "\n",
        "Best Strategy: [('soft', 30), ('soft', 30), ('soft', 23)]\n",
        "Best Total Time: 5988.977419354838 seconds"
      ],
      "metadata": {
        "id": "jMfNBV63wjmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Car-Parameters, to see, if optimized values are actually better than other values."
      ],
      "metadata": {
        "id": "TqLe2liv8T-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "print(f'Rear Wing {randint(1, 500)}')\n",
        "print(f'Engine {randint(1, 500)}')\n",
        "print(f'Front Wing {randint(1, 500)}')\n",
        "print(f'Brakebalance {randint(1, 500)}')\n",
        "print(f'Differential {randint(1, 500)}')\n",
        "print(f'Suspension {randint(1, 500)}')\n",
        "\n"
      ],
      "metadata": {
        "id": "WMpm0v-d5b_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1LiOt7yQL5T"
      },
      "source": [
        "# **Analytics for Race 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AllInOne Optimization"
      ],
      "metadata": {
        "id": "gaek7r_g2y4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZcWkDUrQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sSk6H0gbDmEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna_dashboard"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GaIizzO0-fLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning for Full LGBM"
      ],
      "metadata": {
        "id": "KEAdErdH2qho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    X = df.drop(columns=['Lap Distance', 'Lap Time', 'Avg Speed'])\n",
        "    y = df[\"Avg Speed\"]\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=100,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        #rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gfu5XKfCDNOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning for two datasets\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV2_6.csv\")\n",
        "\n",
        "# Calculate target: Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0  # Adjust this ratio to control importance (10000/40 = 250)\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Prepare features and target\n",
        "X = df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\",\"Round\", \"Track\", \"Qualifying\", \"Stint\", \"Lap\", \"Fuel\", \"Tyre Remaining\", \"Tyre Choice\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        w_train, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=1000,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T7NHt2Z04N5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### R^2 Test LightGBM"
      ],
      "metadata": {
        "id": "lSp_Yhl7Dm9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 242,\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.0645474493988489,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9427185636727835,\n",
        "    'bagging_fraction': 0.785711983453578,\n",
        "    'bagging_freq': 2,\n",
        "    'lambda_l1': 0.6006835353397709,\n",
        "    'lambda_l2': 1.4905819957883624,\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    }\n",
        "\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores = []\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # LightGBM Dataset\n",
        "    lgb_train = lgb.Dataset(X_train, y_train)\n",
        "\n",
        "    # Train model\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_set=lgb_train,\n",
        "        num_boost_round=300  )\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_val)\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "    print(f\"Fold R^2 Score: {r2:.4f}\")\n",
        "\n",
        "# Overall R^2\n",
        "print(f\"\\nAverage R^2 Score: {np.mean(r2_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "-BbmAyMtTs13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training LGBM-Model with Simulator_Data and optm. Hyperparameters"
      ],
      "metadata": {
        "id": "fa53UW9MDxas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 242,\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.0645474493988489,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9427185636727835,\n",
        "    'bagging_fraction': 0.785711983453578,\n",
        "    'bagging_freq': 2,\n",
        "    'lambda_l1': 0.6006835353397709,\n",
        "    'lambda_l2': 1.4905819957883624,\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"best_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'best_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "8UuMHCcezFBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Directly trained LGBM-Model with Simulator_Data and Practice_data using optm. Hyperparameters\n",
        "#Hyperparameters optm. for Simulator and Practice_data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV2_6.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "# Make sure both have the same columns in the same order\n",
        "required_cols = [\"Lap Distance\", \"Lap Time\", \"Avg Speed\", \"weight\", \"Rear Wing\", \"Front Wing\", \"Engine\", \"Brake Balance\", \"Differential\", \"Suspension\", \"Cornering\", \"Inclines\", \"Camber\", \"Grip\", \"Altitude\", \"Roughness\", \"Width\", \"Temperature\", \"Humidity\", \"Wind (Avg. Speed)\", \"Wind (Gusts)\", \"Air Density\", \"Air Pressure\"] + \\\n",
        "                [col for col in sim_df.columns if col not in [\"Lap Distance\", \"Lap Time\", \"Avg Speed\", \"weight\", \"Rear Wing\", \"Front Wing\", \"Engine\", \"Brake Balance\", \"Differential\", \"Suspension\", \"Cornering\", \"Inclines\", \"Camber\", \"Grip\", \"Altitude\", \"Roughness\", \"Width\", \"Temperature\", \"Humidity\", \"Wind (Avg. Speed)\", \"Wind (Gusts)\", \"Air Density\", \"Air Pressure\"]]\n",
        "\n",
        "sim_df = sim_df[required_cols]\n",
        "prac_df = prac_df[required_cols]\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\", \"weight\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "# Parameters (already tuned)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 74,\n",
        "    'max_depth': 11,\n",
        "    'learning_rate': 0.028870630893942515,\n",
        "    'min_data_in_leaf': 13,\n",
        "    'feature_fraction': 0.7399238619191133,\n",
        "    'bagging_fraction': 0.9203471068533383,\n",
        "    'bagging_freq': 6,\n",
        "    'lambda_l1': 0.025758523534949052,\n",
        "    'lambda_l2': 0.9073066525703107}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"sim_prac_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'sim_prac_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "iIDwVfsI9h59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving previously traind LGBM-Model using Pracice_Data"
      ],
      "metadata": {
        "id": "8JIu4WehEAwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the original model\n",
        "model = lgb.Booster(model_file=\"best_lgbm_model.txt\")\n",
        "\n",
        "# Load the new data\n",
        "new_df = pd.read_csv(\"practice_dataV2_5.csv\")\n",
        "\n",
        "# Compute Avg Speed for new data\n",
        "new_df[\"Avg Speed\"] = (new_df[\"Lap Distance\"] / new_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Prepare features and target\n",
        "X_new = new_df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\",\"Round\", \"Track\", \"Qualifying\", \"Stint\", \"Lap\", \"Fuel\", \"Tyre Remaining\", \"Tyre Choice\"])\n",
        "y_new = new_df[\"Avg Speed\"]\n",
        "\n",
        "# Assign higher weights (e.g., 10x more important)\n",
        "sample_weight = [1000] * len(y_new)\n",
        "\n",
        "# Create new LightGBM Dataset\n",
        "new_data = lgb.Dataset(X_new, label=y_new, weight=sample_weight)\n",
        "\n",
        "# Continue training from previous model\n",
        "model = lgb.train(\n",
        "    params={},  # Empty here since model already knows them\n",
        "    train_set=new_data,\n",
        "    init_model=model,\n",
        "    num_boost_round=1000,  # You can increase if needed\n",
        ")\n",
        "\n",
        "# Save updated model\n",
        "model.save_model(\"best_lgbm_model_updated.txt\")\n",
        "\n",
        "print(\"Model updated with new data and saved to 'best_lgbm_model_updated.txt'\")\n"
      ],
      "metadata": {
        "id": "wH98NNhn3Z7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Used to test prediction performance against practice_data"
      ],
      "metadata": {
        "id": "2mSYqbY-EM3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = lgb.Booster(model_file=\"best_lgbm_model.txt\")\n",
        "\n",
        "# Load the test data\n",
        "test_df = pd.read_csv(\"practice_data_snd_half.csv\")\n",
        "\n",
        "# Calculate actual average speed\n",
        "test_df[\"Actual Avg Speed\"] = (test_df[\"Lap Distance\"] / test_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Prepare the test features (same feature engineering as training)\n",
        "X_test = test_df.drop(columns=[\"Actual Avg Speed\", \"Lap Distance\", \"Lap Time\",\"Round\", \"Track\", \"Qualifying\", \"Stint\", \"Lap\", \"Fuel\", \"Tyre Remaining\", \"Tyre Choice\"])\n",
        "\n",
        "# Predict using the model\n",
        "test_df[\"Predicted Avg Speed\"] = model.predict(X_test)\n",
        "\n",
        "# Calculate difference\n",
        "test_df[\"Difference\"] = test_df[\"Predicted Avg Speed\"] - test_df[\"Actual Avg Speed\"]\n",
        "\n",
        "# Output the results\n",
        "print(test_df[[\"Predicted Avg Speed\", \"Actual Avg Speed\", \"Difference\"]])\n",
        "\n",
        "# Summary statistics\n",
        "mae = np.mean(np.abs(test_df[\"Difference\"]))\n",
        "rmse = np.sqrt(np.mean(test_df[\"Difference\"] ** 2))\n",
        "max_diff = np.max(np.abs(test_df[\"Difference\"]))\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"Maximum Absolute Difference: {max_diff:.2f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Xx99yt_r4Fmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter Optimization"
      ],
      "metadata": {
        "id": "JwwlFnR2JJwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "\n",
        "# Load trained model\n",
        "#model = lgb.Booster(model_file=\"best_lgbm_model_updated.txt\")\n",
        "model = lgb.Booster(model_file=\"sim_prac_lgbm_model.txt\")\n",
        "\n",
        "# Load track/weather data (single row)\n",
        "track_weather = pd.read_csv(\"track_weather_germany.csv\")\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    # Suggest car parameters\n",
        "    params = {\n",
        "        \"Engine\": trial.suggest_int(\"Engine\", 1, 500),\n",
        "        \"Rear Wing\": trial.suggest_int(\"Rear Wing\", 1, 500),\n",
        "        \"Front Wing\": trial.suggest_int(\"Front Wing\", 1, 500),\n",
        "        \"Brake Balance\": trial.suggest_int(\"Brake Balance\", 1, 500),\n",
        "        \"Suspension\": trial.suggest_int(\"Suspension\", 1, 500),\n",
        "        \"Differential\": trial.suggest_int(\"Differential\", 1, 500),\n",
        "    }\n",
        "#Engine: 91\n",
        "#Differential: 101\n",
        "#RearWing: 489\n",
        "#FrontWing: 274\n",
        "#Suspension: 45\n",
        "#BrakeBalance: 101\n",
        "\n",
        "    # Combine with static track/weather parameters\n",
        "    input_data = pd.concat([track_weather, pd.DataFrame([params])], axis=1)\n",
        "\n",
        "    # Predict average speed\n",
        "    predicted_avg_speed = model.predict(input_data)[0]\n",
        "\n",
        "    # We want to maximize speed\n",
        "    return -predicted_avg_speed\n",
        "\n",
        "# Create study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "\n",
        "# Optimize\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Output best results\n",
        "best_trial = study.best_trial\n",
        "print(\"\\nBest Parameters:\")\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "print(f\"Predicted Avg Speed: {-best_trial.value:.2f}\")"
      ],
      "metadata": {
        "id": "GZv70c6f9aTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Best Parameters:\n",
        "Engine: 133\n",
        "Rear Wing: 39\n",
        "Front Wing: 67\n",
        "Brake: 217\n",
        "Suspension: 95\n",
        "Differential: 88\n",
        "Predicted Avg Speed: --187.46\n",
        "\n",
        "Engine: 91\n",
        "Differential: 101\n",
        "RearWing: 489\n",
        "FrontWing: 274\n",
        "Suspension: 45\n",
        "BrakeBalance: 101"
      ],
      "metadata": {
        "id": "9dwmXQnPUNM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the intervals around the supposedly optimal parameters\n"
      ],
      "metadata": {
        "id": "tjXh9FR_eX8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "import threading\n",
        "\n",
        "# Load trained model\n",
        "#model = lgb.Booster(model_file=\"best_lgbm_model_updated.txt\")\n",
        "model = lgb.Booster(model_file=\"best_lgbm_model.txt\")\n",
        "\n",
        "# Load track/weather data (single row)\n",
        "track_weather = pd.read_csv(\"track_weather_germany.csv\")\n",
        "\n",
        "# Store all best results\n",
        "all_best_results = []\n",
        "\n",
        "# Optional: Start dashboard for one of the runs\n",
        "def run_dashboard(study):\n",
        "    run_server(study)\n",
        "\n",
        "# Run 20 optimization loops\n",
        "for run in range(1, 11):\n",
        "    print(f\"\\n🔁 Optimization Run {run}/20\")\n",
        "\n",
        "    # Define objective function (wrapped inside loop to keep it clean)\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            \"Engine\": trial.suggest_int(\"Engine\", 85, 115),\n",
        "            \"Rear Wing\": trial.suggest_int(\"Rear Wing\", 499, 500),\n",
        "            \"Front Wing\": trial.suggest_int(\"Front Wing\", 70, 90),\n",
        "            \"Brake\": trial.suggest_int(\"Brake\", 85, 115),\n",
        "            \"Suspension\": trial.suggest_int(\"Suspension\", 20, 50),\n",
        "            \"Differential\": trial.suggest_int(\"Differential\", 68, 98),\n",
        "        }\n",
        "\n",
        "#Engine:         91  +-30    => 85 - 115\n",
        "#Differential:  101  +-30    => 68 - 98\n",
        "#RearWing:      489  +-125   => 499 - 500\n",
        "#FrontWing:     274  +-125   => 70 - 90\n",
        "#Suspension:     45  +-125  => 20 - 50\n",
        "#BrakeBalance:  101  +-125   => 85 - 115\n",
        "\n",
        "        input_data = pd.concat([track_weather, pd.DataFrame([params])], axis=1)\n",
        "        predicted_avg_speed = model.predict(input_data)[0]\n",
        "        return predicted_avg_speed  # maximize speed\n",
        "\n",
        "    # Create a new study for each run\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "\n",
        "    # Run optimization (adjust trials as needed)\n",
        "    study.optimize(objective, n_trials=100)\n",
        "\n",
        "    # Collect results\n",
        "    best_trial = study.best_trial\n",
        "    result = {\n",
        "        \"Run\": run,\n",
        "        \"Predicted Avg Speed\": best_trial.value,\n",
        "        **best_trial.params\n",
        "    }\n",
        "    all_best_results.append(result)\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(all_best_results)\n",
        "print(\"\\n📊 Summary of All Runs:\")\n",
        "print(results_df)\n",
        "\n",
        "# Optionally save to CSV\n",
        "results_df.to_csv(\"optimization_results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "UZyHIfdAA4Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Engine:         91  +-30    => 61 - 121\n",
        "#Differential:  101  +-30    => 51 - 151\n",
        "#RearWing:      489  +-125   => 364 - 500\n",
        "#FrontWing:     274  +-125   => 149 - 399\n",
        "#Suspension:     45  +-125  => 5 - 170\n",
        "#BrakeBalance:  101  +-125   => 0 - 226"
      ],
      "metadata": {
        "id": "lSkcp0gsWA3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "📊 Summary of All Runs: (ohne update)\n",
        "   Run  Predicted Avg Speed  Engine  Rear Wing  Front Wing  Brake  Suspension  \\\n",
        "0    1           186.038712      89        411         170    100          91\n",
        "1    2           185.970222     111        369         156    210          80\n",
        "2    3           186.081557     111        478         163    101          82\n",
        "3    4           185.960439     105        496         154    176          97\n",
        "4    5           185.998318      93        445         198    121          99\n",
        "5    6           186.093750     109        427         152    107          98\n",
        "6    7           186.047609      89        463         198    116          92\n",
        "7    8           186.013795     110        459         149     99          88\n",
        "8    9           186.048086      94        437         155    101         106\n",
        "9   10           186.066058      90        388         158    114          94\n",
        "\n",
        "   Differential\n",
        "0            86\n",
        "1            82\n",
        "2            83\n",
        "3            94\n",
        "4            82\n",
        "5            82\n",
        "6            83\n",
        "7           100\n",
        "8            91\n",
        "9            85"
      ],
      "metadata": {
        "id": "kCGkj75KXB0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CEjrFYansSCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Optimization LightGBM"
      ],
      "metadata": {
        "id": "M_Txp08_sVwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schritte:\n",
        "\n",
        "1. Which Car-Parameters should use which track/weather-parameters\n",
        "\n",
        "2. In what order should the Car-Parameters be optimized?\n",
        "\n",
        "3. Write Code, that optimizes each Models Hyperparameters using Optuna and K-Fold-cross-validation.\n",
        "\n",
        "4. Train and Save each Model with full data set (no Train/Test-Split)\n",
        "\n",
        "5. Optimize Models using Practice_Data\n",
        "\n",
        "6. Write Code, that sequentially optimizes Car-Parameters with existing Models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IW2dhvstsfJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Step: Which Car-Parameters should use which track/weather-parameters?\n"
      ],
      "metadata": {
        "id": "DvpEBv-CuDsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Rear Wing\n",
        " - Air Density\n",
        " - Cornering\n",
        " - Air Pressure\n",
        " - Inclines\n",
        " - Wind (Avg. Speed)\n",
        " - Humidity\n",
        " - Roughness\n",
        "\n",
        "Engine\n",
        " - Grip\n",
        " - Humidity\n",
        " - Air Density\n",
        " - Altitude\n",
        " - Temperature\n",
        " - Inclines\n",
        " - Air Pressure\n",
        " - Cornering\n",
        "\n",
        "Front Wing\n",
        " - Cornering\n",
        " - Air Pressure\n",
        " - Air Density\n",
        " - Inclines\n",
        " - Wind (Avg. Speed)\n",
        " - Humidity\n",
        " - Wind (Gusts)\n",
        "\n",
        "Brake Balance\n",
        " - Cornering\n",
        " - Width\n",
        " - Roughness\n",
        " - Temperature\n",
        "\n",
        "Differential\n",
        " - Cornering\n",
        " - Width\n",
        " - Inclines\n",
        " - Grip\n",
        " - Temperature\n",
        " - Air Density\n",
        "\n",
        "Suspension\n",
        " - Grip\n",
        " - Inclines\n",
        " - Cornering\n",
        " - Camber\n",
        " - Roughness\n",
        " - Width"
      ],
      "metadata": {
        "id": "2EYjgPWkveBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Define inputs (track/weather features) and targets (car parameters)\n",
        "track_weather_features = [\n",
        "    'Cornering', 'Inclines', 'Camber', 'Grip',\n",
        "    'Wind (Avg. Speed)', 'Temperature', 'Humidity', 'Air Density',\n",
        "    'Air Pressure', 'Wind (Gusts)', 'Altitude', 'Roughness', 'Width'\n",
        "]\n",
        "\n",
        "car_setup_params = ['Rear Wing', 'Engine', 'Front Wing', 'Brake Balance', 'Differential', 'Suspension']\n",
        "\n",
        "# Store feature importances for each car parameter\n",
        "feature_importance_dict = {}\n",
        "\n",
        "# Loop through car parameters\n",
        "for param in car_setup_params:\n",
        "    X = df[track_weather_features]\n",
        "    y = df[param]\n",
        "\n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = LGBMRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate R² score\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n{param} - R²: {score:.3f}\")\n",
        "\n",
        "    # Get feature importances and filter by importance > 0.1\n",
        "    importances = model.booster_.feature_importance(importance_type='gain')\n",
        "    importance_series = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Store importances\n",
        "    feature_importance_dict[param] = importance_series\n",
        "\n",
        "    # Display the features with importance > 0.075\n",
        "    print(f\"\\nFor {param}, track/weather parameters with importance > 0.075:\")\n",
        "    for feature, importance in importance_series.items():\n",
        "        if importance > 0.075:\n",
        "            print(f\" - {feature}: {importance:.3f}\")\n",
        "\n",
        "    # Optional: Plot feature importances\n",
        "    importance_series.plot(kind='barh', title=f\"Feature Importance for {param}\", figsize=(8, 5))\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5dN_q0RDuADO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second Step: In what order should the Car-Parameters be optimized?"
      ],
      "metadata": {
        "id": "AihzvPHiv54j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Engine\n",
        "2. Differential\n",
        "3. Rear Wing\n",
        "4. Front Wing\n",
        "5. Suspension\n",
        "6. Break Balance"
      ],
      "metadata": {
        "id": "CAwkPifgwNTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Define X and y\n",
        "X = df.drop(columns=['Lap Distance', 'Lap Time', 'Avg Speed'])\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Set the hyperparameters\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 242,\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.0645474493988489,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9427185636727835,\n",
        "    'bagging_fraction': 0.785711983453578,\n",
        "    'bagging_freq': 2,\n",
        "    'lambda_l1': 0.6006835353397709,\n",
        "    'lambda_l2': 1.4905819957883624,\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "train_data = lgb.Dataset(X, label=y)\n",
        "model = lgb.train(params,\n",
        "                  train_data,\n",
        "                  num_boost_round=100)\n",
        "\n",
        "# Get feature importance by 'split' and 'gain'\n",
        "importance_split = model.feature_importance(importance_type='split')\n",
        "importance_gain = model.feature_importance(importance_type='gain')\n",
        "\n",
        "# Sort feature importance by 'split'\n",
        "sorted_split_idx = importance_split.argsort()[::1]\n",
        "sorted_split_importance = importance_split[sorted_split_idx]\n",
        "sorted_split_features = X.columns[sorted_split_idx]\n",
        "\n",
        "# Sort feature importance by 'gain'\n",
        "sorted_gain_idx = importance_gain.argsort()[::1]\n",
        "sorted_gain_importance = importance_gain[sorted_gain_idx]\n",
        "sorted_gain_features = X.columns[sorted_gain_idx]\n",
        "\n",
        "# Plot feature importance by 'split'\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(sorted_split_features, sorted_split_importance , color='red')\n",
        "plt.title('Feature Importance by Split')\n",
        "plt.xlabel('Number of Splits')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n",
        "\n",
        "# Plot feature importance by 'gain'\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(sorted_gain_features, sorted_gain_importance, color='blue')\n",
        "plt.title('Feature Importance by Gain')\n",
        "plt.xlabel('Gain')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Hn0-UX1vv-Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Third Step: Write Code, that optimizes each Models Hyperparameters using Optuna and K-Fold-cross-validation."
      ],
      "metadata": {
        "id": "vCbFxwAXwaIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimized Hyperparameters:\n",
        "Engine:\n",
        "{'num_leaves': 281, 'max_depth': 11, 'learning_rate': 0.04083240077095524, 'min_data_in_leaf': 96, 'feature_fraction': 0.9534759457760267, 'bagging_fraction': 0.6637656869307713, 'bagging_freq': 7, 'lambda_l1': 0.48486124811843856, 'lambda_l2': 1.0469435993282974}\n",
        "Differential:\n",
        "{'num_leaves': 126, 'max_depth': 8, 'learning_rate': 0.05725939263903659, 'min_data_in_leaf': 96, 'feature_fraction': 0.9048274481436259, 'bagging_fraction': 0.6871315558035545, 'bagging_freq': 1, 'lambda_l1': 2.9809700145880162, 'lambda_l2': 2.893530172381254}\n",
        "Rear Wing:\n",
        "{'num_leaves': 41, 'max_depth': 14, 'learning_rate': 0.07379289439034513, 'min_data_in_leaf': 14, 'feature_fraction': 0.9805583874353474, 'bagging_fraction': 0.757494844528942, 'bagging_freq': 1, 'lambda_l1': 3.3280185770912905, 'lambda_l2': 4.668868493827121}\n",
        "Front Wing:\n",
        "{'num_leaves': 228, 'max_depth': 6, 'learning_rate': 0.10991909073754202, 'min_data_in_leaf': 94, 'feature_fraction': 0.954670793846081, 'bagging_fraction': 0.7659843231590522, 'bagging_freq': 1, 'lambda_l1': 3.8616883301361553, 'lambda_l2': 4.896984209036385}\n",
        "Suspension:\n",
        "{'num_leaves': 31, 'max_depth': 10, 'learning_rate': 0.14051851191638579, 'min_data_in_leaf': 75, 'feature_fraction': 0.999888882811791, 'bagging_fraction': 0.7009625088481276, 'bagging_freq': 1, 'lambda_l1': 4.8851994495913145, 'lambda_l2': 3.6824821872767783}\n",
        "Break Balance:\n",
        "{'num_leaves': 27, 'max_depth': 11, 'learning_rate': 0.18696777761444966, 'min_data_in_leaf': 73, 'feature_fraction': 0.964098272670725, 'bagging_fraction': 0.8852821315081366, 'bagging_freq': 10, 'lambda_l1': 3.486399193949678, 'lambda_l2': 3.7053586457221366}"
      ],
      "metadata": {
        "id": "af_mRuKP2NuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### HP-optimization code for each Car-Param."
      ],
      "metadata": {
        "id": "6wPBhGNqDqh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Optimization Engine\n",
        "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    X = df[['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure' , 'Cornering']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=100,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        #rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FlBxc04rw-MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Optimization Differential\n",
        "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    X = df[['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=100,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        #rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UJ7o8EcIzwfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Optimization Rear Wing\n",
        "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    X = df[['Rear Wing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure' , 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=100,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        #rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G1WltfoG0XDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Optimization Front Wing\n",
        "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    X = df[['Front Wing', 'Rear Wing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=100,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        #rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "vf9k6sWp0YYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Optimization Suspension\n",
        "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    X = df[['Suspension', 'Front Wing', 'Rear Wing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=100,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        #rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "0peIPcB80ZSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Optimization Brake Balance\n",
        "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"])*3600\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    X = df[['Brake Balance', 'Suspension', 'Front Wing', 'Rear Wing', 'Differential', 'Engine','Cornering', 'Width', 'Roughness', 'Temperature']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=100,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        #rmse = mean_squared_error(y_val, preds, squared=False)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "Xdamwe740aPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fourth Step: Train and Save each Model with full data set (no Train/Test-Split)"
      ],
      "metadata": {
        "id": "KF_qUNre8BP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Brake Balance: \tX = df[['Brake_Balance', 'Suspension', 'Front_Wing', 'Rear_Wing', 'Differential', 'Engine','Cornering', 'Width', 'Roughness', 'Temperature']]\n",
        "Suspension: \tX = df[['Suspension', 'Front_Wing', 'Rear_Wing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width']]\n",
        "Front Wing: \tX = df[['Front_Wing', 'Rear_Wing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)']]\n",
        "Rear Wing: \tX = df[['Rear_Wing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure' , 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness']]\n",
        "Differential: \tX = df[['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density']]\n",
        "Engine: \tX = df[['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure' , 'Cornering']]"
      ],
      "metadata": {
        "id": "lDZ_Uj7sAJrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimized Hyperparameters:\n",
        "Engine:\n",
        "{'num_leaves': 281, 'max_depth': 11, 'learning_rate': 0.04083240077095524, 'min_data_in_leaf': 96, 'feature_fraction': 0.9534759457760267, 'bagging_fraction': 0.6637656869307713, 'bagging_freq': 7, 'lambda_l1': 0.48486124811843856, 'lambda_l2': 1.0469435993282974}\n",
        "Differential:\n",
        "{'num_leaves': 126, 'max_depth': 8, 'learning_rate': 0.05725939263903659, 'min_data_in_leaf': 96, 'feature_fraction': 0.9048274481436259, 'bagging_fraction': 0.6871315558035545, 'bagging_freq': 1, 'lambda_l1': 2.9809700145880162, 'lambda_l2': 2.893530172381254}\n",
        "Rear Wing:\n",
        "{'num_leaves': 41, 'max_depth': 14, 'learning_rate': 0.07379289439034513, 'min_data_in_leaf': 14, 'feature_fraction': 0.9805583874353474, 'bagging_fraction': 0.757494844528942, 'bagging_freq': 1, 'lambda_l1': 3.3280185770912905, 'lambda_l2': 4.668868493827121}\n",
        "Front Wing:\n",
        "{'num_leaves': 228, 'max_depth': 6, 'learning_rate': 0.10991909073754202, 'min_data_in_leaf': 94, 'feature_fraction': 0.954670793846081, 'bagging_fraction': 0.7659843231590522, 'bagging_freq': 1, 'lambda_l1': 3.8616883301361553, 'lambda_l2': 4.896984209036385}\n",
        "Suspension:\n",
        "{'num_leaves': 31, 'max_depth': 10, 'learning_rate': 0.14051851191638579, 'min_data_in_leaf': 75, 'feature_fraction': 0.999888882811791, 'bagging_fraction': 0.7009625088481276, 'bagging_freq': 1, 'lambda_l1': 4.8851994495913145, 'lambda_l2': 3.6824821872767783}\n",
        "Break Balance:\n",
        "{'num_leaves': 27, 'max_depth': 11, 'learning_rate': 0.18696777761444966, 'min_data_in_leaf': 73, 'feature_fraction': 0.964098272670725, 'bagging_fraction': 0.8852821315081366, 'bagging_freq': 10, 'lambda_l1': 3.486399193949678, 'lambda_l2': 3.7053586457221366}"
      ],
      "metadata": {
        "id": "JCrHVq0gAq5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code to build Model for each Car-Param."
      ],
      "metadata": {
        "id": "a-gKI-dEDyTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"_newnames\" explained:**\n",
        "because of how the following code works, the coloums in the Data need to have names, that fit a certain scheme. The coloums cant have blank spaces between words, the blank spaces can also not be replaced with underscores (_).\n",
        "Also the trained Models need to have the exact same name, as their corresponding car-parameter.\n",
        "\n",
        "Rear Wing: RearWing\n",
        "\n",
        "Front Wing: FrontWing\n",
        "\n",
        "Brake: BrakeBalance\n",
        "\n",
        "This needs to be done for Simulator and Practice_Data."
      ],
      "metadata": {
        "id": "N9OSmZoQEtwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Engine (Hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure' , 'Cornering']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 281,\n",
        "    'max_depth': 11,\n",
        "    'learning_rate': 0.04083240077095524,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9534759457760267,\n",
        "    'bagging_fraction': 0.6637656869307713,\n",
        "    'bagging_freq': 7,\n",
        "    'lambda_l1': 0.48486124811843856,\n",
        "    'lambda_l2': 1.0469435993282974\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Engine_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Engine_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "fzDzzWhV-DKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Differential (Hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 126,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05725939263903659,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9048274481436259,\n",
        "    'bagging_fraction': 0.6871315558035545,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 2.9809700145880162,\n",
        "    'lambda_l2': 2.893530172381254\n",
        "    }\n",
        "\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Differential_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Differential_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "R0aao5t5EOOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rear Wing (Hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure' , 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 41,\n",
        "    'max_depth': 14,\n",
        "    'learning_rate': 0.07379289439034513,\n",
        "    'min_data_in_leaf': 14,\n",
        "    'feature_fraction': 0.9805583874353474,\n",
        "    'bagging_fraction': 0.757494844528942,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 3.3280185770912905,\n",
        "    'lambda_l2': 4.668868493827121\n",
        "    }\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"RearWing_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'RearWing_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "beEB37hDEOfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Front Wing (hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 228,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.10991909073754202,\n",
        "    'min_data_in_leaf': 94,\n",
        "    'feature_fraction': 0.954670793846081,\n",
        "    'bagging_fraction': 0.7659843231590522,\n",
        "    'bagging_freq': 1, 'lambda_l1': 3.8616883301361553,\n",
        "    'lambda_l2': 4.896984209036385\n",
        "    }\n",
        "\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"FrontWing_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'FrontWing_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "rJwvOAD2EOsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Suspension\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': 10,\n",
        "    'learning_rate': 0.14051851191638579,\n",
        "    'min_data_in_leaf': 75,\n",
        "    'feature_fraction': 0.999888882811791,\n",
        "    'bagging_fraction': 0.7009625088481276,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 4.8851994495913145,\n",
        "    'lambda_l2': 3.6824821872767783\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Suspension_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Suspension_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "tjumQ9BPEO8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Brake Balance (hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine','Cornering', 'Width', 'Roughness', 'Temperature']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 27,\n",
        "    'max_depth': 11,\n",
        "    'learning_rate': 0.18696777761444966,\n",
        "    'min_data_in_leaf': 73,\n",
        "    'feature_fraction': 0.964098272670725,\n",
        "    'bagging_fraction': 0.8852821315081366,\n",
        "    'bagging_freq': 10,\n",
        "    'lambda_l1': 3.486399193949678,\n",
        "    'lambda_l2': 3.7053586457221366\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"BrakeBalance_lgbm_model.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'BrakeBalance_lgbm_model.txt'\")\n"
      ],
      "metadata": {
        "id": "GWo_8vq7EPNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fifth Step: Optimize Models using Practice_Data"
      ],
      "metadata": {
        "id": "QgJHT3_ZS1m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Model names\n",
        "model_names = [\n",
        "    \"Engine_lgbm_model.txt\",\n",
        "    \"Differential_lgbm_model.txt\",\n",
        "    \"RearWing_lgbm_model.txt\",\n",
        "    \"FrontWing_lgbm_model.txt\",\n",
        "    \"Suspension_lgbm_model.txt\",\n",
        "    \"BrakeBalance_lgbm_model.txt\"\n",
        "]\n",
        "\n",
        "# Corresponding feature sets\n",
        "feature_sets = {\n",
        "    \"Engine\": ['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure', 'Cornering'],\n",
        "    \"Differential\": ['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density'],\n",
        "    \"RearWing\": ['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness'],\n",
        "    \"FrontWing\": ['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)'],\n",
        "    \"Suspension\": ['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width'],\n",
        "    \"BrakeBalance\": ['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Width', 'Roughness', 'Temperature']\n",
        "}\n",
        "\n",
        "# Load new data\n",
        "df = pd.read_csv(\"practice_data_newnamesV2_5.csv\")\n",
        "\n",
        "# Compute Avg Speed for new data\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Target variable\n",
        "y_new = df[\"Avg Speed\"]\n",
        "\n",
        "# Sample weight\n",
        "sample_weight = [1000] * len(y_new)\n",
        "\n",
        "# Training each model with its feature set\n",
        "for model_file in model_names:\n",
        "    model_key = model_file.split(\"_\")[0]  # Extract the prefix e.g., \"Engine\"\n",
        "    features = feature_sets[model_key]\n",
        "\n",
        "    print(f\"\\nUpdating {model_file} with features: {features}\")\n",
        "\n",
        "    # Prepare feature matrix\n",
        "    X_new = df[features]\n",
        "\n",
        "    # Load existing model\n",
        "    model = lgb.Booster(model_file=model_file)\n",
        "\n",
        "    # Create dataset\n",
        "    new_data = lgb.Dataset(X_new, label=y_new, weight=sample_weight)\n",
        "\n",
        "    # Continue training\n",
        "    updated_model = lgb.train(\n",
        "        params={},\n",
        "        train_set=new_data,\n",
        "        init_model=model,\n",
        "        num_boost_round=1000\n",
        "    )\n",
        "\n",
        "    # Save updated model\n",
        "    updated_file = model_file.replace(\".txt\", \"_updated.txt\")\n",
        "    updated_model.save_model(updated_file)\n",
        "\n",
        "    print(f\"Model saved to {updated_file}\")\n",
        "\n",
        "print(\"\\nAll models updated successfully.\")\n"
      ],
      "metadata": {
        "id": "3UVmIWEOTC2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sixth Step: Write Code, that sequentially optimizes Car-Parameters with existing Models"
      ],
      "metadata": {
        "id": "vU4q8VKYUcSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v709LFLFbFhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "# Ordered list of parameters to optimize\n",
        "params_to_optimize = [\"Engine\", \"Differential\", \"RearWing\", \"FrontWing\", \"Suspension\", \"BrakeBalance\"]\n",
        "\n",
        "# Corresponding feature sets for each model\n",
        "feature_sets = {\n",
        "    \"Engine\": ['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure', 'Cornering'],\n",
        "    \"Differential\": ['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density'],\n",
        "    \"RearWing\": ['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness'],\n",
        "    \"FrontWing\": ['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)'],\n",
        "    \"Suspension\": ['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width'],\n",
        "    \"BrakeBalance\": ['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Width', 'Roughness', 'Temperature']\n",
        "}\n",
        "\n",
        "# Load static track & weather data\n",
        "base_data = pd.read_csv(\"track_weather_germany.csv\")\n",
        "\n",
        "# This will hold the best parameter values as we optimize them\n",
        "optimized_params = {}\n",
        "\n",
        "# Begin sequential optimization\n",
        "for car_part in params_to_optimize:\n",
        "    print(f\"\\n🔧 Optimizing {car_part}...\")\n",
        "\n",
        "    model_path = f\"{car_part}_lgbm_model_updated.txt\"\n",
        "    model = lgb.Booster(model_file=model_path)\n",
        "    features = feature_sets[car_part]\n",
        "\n",
        "    def objective(trial):\n",
        "        # Set the current parameter being optimized\n",
        "\n",
        "        params = {\n",
        "            \"Engine\": trial.suggest_int(\"Engine\", 85, 115),\n",
        "            \"RearWing\": trial.suggest_int(\"RearWing\", 499, 500),\n",
        "            \"FrontWing\": trial.suggest_int(\"FrontWing\", 70, 90),\n",
        "            \"BrakeBalance\": trial.suggest_int(\"BrakeBalance\", 85, 115),\n",
        "            \"Suspension\": trial.suggest_int(\"Suspension\", 20, 50),\n",
        "            \"Differential\": trial.suggest_int(\"Differential\", 68, 98),}\n",
        "\n",
        "        current_value = params[car_part]\n",
        "\n",
        "        # Create a single row input with all needed features\n",
        "        input_data = base_data.copy()\n",
        "\n",
        "        # Add previously optimized params\n",
        "        for param, value in optimized_params.items():\n",
        "            input_data[param] = value\n",
        "\n",
        "        # Add current trial value\n",
        "        input_data[car_part] = current_value\n",
        "\n",
        "        # If any missing feature, fill with 0 or a safe default\n",
        "        for col in features:\n",
        "            if col not in input_data.columns:\n",
        "                input_data[col] = 0\n",
        "\n",
        "        # Ensure correct order of features\n",
        "        X = input_data[features]\n",
        "\n",
        "        # Predict Avg Speed\n",
        "        avg_speed = model.predict(X)[0]\n",
        "        return avg_speed  # Optuna maximizes this\n",
        "\n",
        "    # Run Optuna\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=300, show_progress_bar=True)\n",
        "\n",
        "    best_value = study.best_params[car_part]\n",
        "    optimized_params[car_part] = best_value\n",
        "    print(f\"✅ Best {car_part}: {best_value}\")\n",
        "\n",
        "# Final results\n",
        "print(\"\\n🎯 Final Optimized Parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "iOUiyfYXUaJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "477\t166\t89\t97\t83\t35\n",
        "\n",
        "🎯 Final Optimized Parameters: (model without update)\n",
        "Engine: 91\n",
        "Differential: 101\n",
        "RearWing: 489\n",
        "FrontWing: 274\n",
        "Suspension: 45\n",
        "BrakeBalance: 101\n",
        "\n",
        "🎯 Final Optimized Parameters:(model with update)\n",
        "Engine: 32\n",
        "Differential: 1\n",
        "RearWing: 43\n",
        "FrontWing: 68\n",
        "Suspension: 29\n",
        "BrakeBalance: 268"
      ],
      "metadata": {
        "id": "syK5a_0KipDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Race Strategy"
      ],
      "metadata": {
        "id": "QfAjryBIwS2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Define the tire parameters and their lap time formulas\n",
        "def lap_time_super_soft(X):\n",
        "    return (67.1830587725926) + 0.18352607407407 * X\n",
        "\n",
        "def lap_time_soft(X):\n",
        "    return (67.5640573104347) + 0.140194202898552 * X\n",
        "\n",
        "def lap_time_medium(X):\n",
        "    return (68.2222646857471) + 0.142527494252874 * X\n",
        "\n",
        "def lap_time_hard(X):\n",
        "    return (68.9335449948148) + 0.108381851851852 * X\n",
        "\n",
        "# Tire data with their lifespan\n",
        "tire_lifespan = {\n",
        "    \"super_soft\": 9,\n",
        "    \"soft\": 23,\n",
        "    \"medium\": 29,\n",
        "    \"hard\": 36\n",
        "}\n",
        "\n",
        "# Pit stop penalty\n",
        "pit_stop_time = 30  # seconds\n",
        "\n",
        "# Function to calculate the total race time for a given strategy\n",
        "def calculate_race_time(laps, strategy):\n",
        "    total_time = 0\n",
        "    total_pit_stops = 0\n",
        "    lap_index = 0\n",
        "    lap_counter = 0\n",
        "\n",
        "    while lap_counter < laps:\n",
        "        tire, stint_laps = strategy[lap_index]\n",
        "\n",
        "        # Ensure we don't exceed the total laps\n",
        "        if lap_counter + stint_laps > laps:\n",
        "            stint_laps = laps - lap_counter\n",
        "\n",
        "        # Calculate the lap times for this stint\n",
        "        lap_times = []\n",
        "        for i in range(stint_laps):\n",
        "            if tire == \"super_soft\":\n",
        "                lap_times.append(lap_time_super_soft(i + 1))\n",
        "            elif tire == \"soft\":\n",
        "                lap_times.append(lap_time_soft(i + 1))\n",
        "            elif tire == \"medium\":\n",
        "                lap_times.append(lap_time_medium(i + 1))\n",
        "            elif tire == \"hard\":\n",
        "                lap_times.append(lap_time_hard(i + 1))\n",
        "\n",
        "        total_time += sum(lap_times)  # Add the lap times of this stint\n",
        "        lap_counter += stint_laps\n",
        "\n",
        "        # If we are not at the last stint, account for a pit stop\n",
        "        if lap_counter < laps:\n",
        "            total_time += pit_stop_time  # Pit stop penalty\n",
        "            total_pit_stops += 1\n",
        "\n",
        "        lap_index += 1\n",
        "        if lap_index >= len(strategy):\n",
        "            break\n",
        "\n",
        "    return total_time, total_pit_stops\n",
        "\n",
        "# Function to generate possible strategies dynamically\n",
        "def generate_strategies(laps):\n",
        "    strategies = []\n",
        "    tire_choices = [\"super_soft\", \"soft\", \"medium\", \"hard\"]\n",
        "\n",
        "    # Generate strategies by breaking the laps into multiple stints\n",
        "    for tire1 in tire_choices:\n",
        "        for tire2 in tire_choices:\n",
        "            for tire3 in tire_choices:\n",
        "                for tire4 in tire_choices:\n",
        "                  for tire5 in tire_choices:\n",
        "                    strategy = []\n",
        "                    remaining_laps = laps\n",
        "\n",
        "                    # Create dynamic stints for each tire\n",
        "                    for tire in [tire1, tire2, tire3, tire4, tire5]:\n",
        "                    #for tire in [tire1, tire2, tire3, tire4]:\n",
        "                    #for tire in [tire1, tire2, tire3]:\n",
        "                    #for tire in [tire1, tire2]:\n",
        "                        stint_laps = tire_lifespan[tire]\n",
        "\n",
        "                        if remaining_laps > stint_laps:\n",
        "                            strategy.append((tire, stint_laps))\n",
        "                            remaining_laps -= stint_laps\n",
        "                        else:\n",
        "                            strategy.append((tire, remaining_laps))\n",
        "                            break\n",
        "\n",
        "                    if sum([stint[1] for stint in strategy]) == laps:\n",
        "                        strategies.append(strategy)\n",
        "\n",
        "    return strategies\n",
        "\n",
        "# Function to find the best strategy\n",
        "def optimize_strategy(laps):\n",
        "    best_time = math.inf\n",
        "    best_strategy = None\n",
        "\n",
        "    strategies = generate_strategies(laps)\n",
        "\n",
        "    for strategy in strategies:\n",
        "        total_time, pit_stops = calculate_race_time(laps, strategy)\n",
        "        if total_time < best_time:\n",
        "            best_time = total_time\n",
        "            best_strategy = strategy\n",
        "            best_pit_stops = pit_stops\n",
        "\n",
        "    return best_strategy, best_time, best_pit_stops\n",
        "\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    race_laps = 85\n",
        "    best_strategy, best_time, total_pit_stops = optimize_strategy(race_laps)\n",
        "    print(f\"Best Strategy: {best_strategy}\")\n",
        "    print(f\"Best Total Time: {best_time} seconds\")\n",
        "    print(f\"Total Pit Stops: {total_pit_stops}\")"
      ],
      "metadata": {
        "id": "Mtb9mV-1wVmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best Strategy: [('soft', 23), ('soft', 23), ('soft', 23), ('soft', 14)]\n",
        "Best Total Time: 5828.617948070432 seconds\n",
        "Total Pit Stops: 3"
      ],
      "metadata": {
        "id": "CS15anDxxnQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZneIB62QL5T"
      },
      "source": [
        "# **Analytics for Race 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdHKUysbQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Optimization"
      ],
      "metadata": {
        "id": "IFBPGD5iF9Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "4GpYLQnx6GlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Optimization Sim Prac Combo"
      ],
      "metadata": {
        "id": "jPfGsw1syZAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Engine SimPrac Hyperparameter Optimization\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV3_3.csv\")\n",
        "\n",
        "# Calculate target: Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0  # Adjust this ratio to control importance (10000/40 = 250)\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    X = df[['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure' , 'Cornering']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    weights = df[\"weight\"]\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        w_train, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=1000,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=250)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "FrYgFIWpyeHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YOY288FF0BuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Differential SimPrac Hyperparameter Optimization\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV3_3.csv\")\n",
        "\n",
        "# Calculate target: Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0  # Adjust this ratio to control importance (10000/40 = 250)\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    X = df[['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    weights = df[\"weight\"]\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        w_train, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=1000,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=250)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "OV_UVw6z0Bx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rear Wing SimPrac Hyperparameter Optimization\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV3_3.csv\")\n",
        "\n",
        "# Calculate target: Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0  # Adjust this ratio to control importance (10000/40 = 250)\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    X = df[['Rear Wing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure' , 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    weights = df[\"weight\"]\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        w_train, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=1000,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=250)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "nLpv6BY21Ie5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Front Wing SimPrac Hyperparameter Optimization\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV3_3.csv\")\n",
        "\n",
        "# Calculate target: Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0  # Adjust this ratio to control importance (10000/40 = 250)\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    X = df[['Front Wing', 'Rear Wing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    weights = df[\"weight\"]\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        w_train, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=1000,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=250)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "wBbm3-Vs1az2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Suspension SimPrac Hyperparameter Optimization\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV3_3.csv\")\n",
        "\n",
        "# Calculate target: Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0  # Adjust this ratio to control importance (10000/40 = 250)\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    X = df[['Suspension', 'Front Wing', 'Rear Wing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    weights = df[\"weight\"]\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        w_train, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=1000,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=250)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "gSEmVmaq1i0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Brake Balance SimPrac Hyperparameter Optimization\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV3_3.csv\")\n",
        "\n",
        "# Calculate target: Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0  # Adjust this ratio to control importance (10000/40 = 250)\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Example: Regression task\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
        "        'force_col_wise': True  # Optional but often speeds things up\n",
        "    }\n",
        "\n",
        "\n",
        "    # K-Fold Cross-Validation\n",
        "    X = df[['Brake Balance', 'Suspension', 'Front Wing', 'Rear Wing', 'Differential', 'Engine','Cornering', 'Width', 'Roughness', 'Temperature']]\n",
        "    y = df[\"Avg Speed\"]\n",
        "    weights = df[\"weight\"]\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        w_train, w_val = weights.iloc[train_idx], weights.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
        "        dvalid = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
        "\n",
        "        model = lgb.train(param, dtrain, num_boost_round=1000,\n",
        "                          valid_sets=[dvalid],\n",
        "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse = np.sqrt(((y_val - preds)**2).mean())\n",
        "        scores.append(rmse)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=300)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)\n"
      ],
      "metadata": {
        "id": "f_X9K3B-1tm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Brake Balance: \tX = df[['Brake_Balance', 'Suspension', 'Front_Wing', 'Rear_Wing', 'Differential', 'Engine','Cornering', 'Width', 'Roughness', 'Temperature']]\n",
        "Suspension: \tX = df[['Suspension', 'Front_Wing', 'Rear_Wing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width']]\n",
        "Front Wing: \tX = df[['Front_Wing', 'Rear_Wing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)']]\n",
        "Rear Wing: \tX = df[['Rear_Wing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure' , 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness']]\n",
        "Differential: \tX = df[['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density']]\n",
        "Engine: \tX = df[['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure' , 'Cornering']]"
      ],
      "metadata": {
        "id": "3Q9vSV_E06Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and saving LGBM-Models for each Car-Parameter (SimPrac Combo)"
      ],
      "metadata": {
        "id": "cXZtPpGb2pcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Best Engine trial:\n",
        "{'num_leaves': 46, 'max_depth': 5, 'learning_rate': 0.033632492994555285, 'min_data_in_leaf': 10, 'feature_fraction': 0.9292816238478901, 'bagging_fraction': 0.6029213489987132, 'bagging_freq': 1, 'lambda_l1': 4.9435895890172095, 'lambda_l2': 1.5835241201372334}\n",
        "\n",
        "Best Differential trial:\n",
        "{'num_leaves': 120, 'max_depth': 4, 'learning_rate': 0.06188740190651351, 'min_data_in_leaf': 10, 'feature_fraction': 0.8516027132719757, 'bagging_fraction': 0.7665333052378347, 'bagging_freq': 2, 'lambda_l1': 4.842140375323366, 'lambda_l2': 0.8572408057266877}\n",
        "\n",
        "Best Rear Wing trial:\n",
        "{'num_leaves': 234, 'max_depth': 8, 'learning_rate': 0.009001605992864, 'min_data_in_leaf': 12, 'feature_fraction': 0.7155500136774263, 'bagging_fraction': 0.9782633351035283, 'bagging_freq': 3, 'lambda_l1': 4.0691300429761625, 'lambda_l2': 0.4270601685583596}\n",
        "\n",
        "Best Front Win trail:\n",
        "{'num_leaves': 75, 'max_depth': 15, 'learning_rate': 0.008393206404444, 'min_data_in_leaf': 10, 'feature_fraction': 0.636593633990795, 'bagging_fraction': 0.8763178958731057, 'bagging_freq': 1, 'lambda_l1': 3.37372395608384, 'lambda_l2': 3.5508540427910322}\n",
        "\n",
        "Best Suspension Trail:\n",
        "{'num_leaves': 94, 'max_depth': 7, 'learning_rate': 0.053319349444258306, 'min_data_in_leaf': 11, 'feature_fraction': 0.7588234798454238, 'bagging_fraction': 0.9663253274432543, 'bagging_freq': 1, 'lambda_l1': 4.443326692620447, 'lambda_l2': 2.017979694136418}\n",
        "\n",
        "Best Brake Balance Trail:\n",
        "{'num_leaves': 52, 'max_depth': 14, 'learning_rate': 0.02166755029862027, 'min_data_in_leaf': 10, 'feature_fraction': 0.5221020637935397, 'bagging_fraction': 0.938010385446846, 'bagging_freq': 1, 'lambda_l1': 2.531857885425292, 'lambda_l2': 4.788757729441045}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QnF8gtni22fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Engine (Hyperparameters and X set) Check\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "prac_df = pd.read_csv(\"practice_data_newnamesV3_2.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df[['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure' , 'Cornering']]\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 46,\n",
        "    'max_depth': 5,\n",
        "    'learning_rate': 0.033632492994555285,\n",
        "    'min_data_in_leaf': 10,\n",
        "    'feature_fraction': 0.9292816238478901,\n",
        "    'bagging_fraction': 0.6029213489987132,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 4.9435895890172095,\n",
        "    'lambda_l2': 1.5835241201372334\n",
        "    }\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Engine_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Engine_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "NWgx-I8k22jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Differential (Hyperparameters and X set) check\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "prac_df = pd.read_csv(\"practice_data_newnamesV3_2.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df[['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density']]\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 120,\n",
        "    'max_depth': 4,\n",
        "    'learning_rate': 0.06188740190651351,\n",
        "    'min_data_in_leaf': 10,\n",
        "    'feature_fraction': 0.8516027132719757,\n",
        "    'bagging_fraction': 0.7665333052378347,\n",
        "    'bagging_freq': 2,\n",
        "    'lambda_l1': 4.842140375323366,\n",
        "    'lambda_l2': 0.8572408057266877\n",
        "    }\n",
        "\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Differential_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Differential_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "I7YlEQUp22jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rear Wing (Hyperparameters and X set) check\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "prac_df = pd.read_csv(\"practice_data_newnamesV3_2.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df[['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure' , 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness']]\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 234,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.009001605992864,\n",
        "    'min_data_in_leaf': 12,\n",
        "    'feature_fraction': 0.7155500136774263,\n",
        "    'bagging_fraction': 0.9782633351035283,\n",
        "    'bagging_freq': 3,\n",
        "    'lambda_l1': 4.0691300429761625,\n",
        "    'lambda_l2': 0.4270601685583596}\n",
        "\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"RearWing_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'RearWing_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "9oGqRigD22jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Front Wing (hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "prac_df = pd.read_csv(\"practice_data_newnamesV3_2.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df[['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)']]\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 75,\n",
        "    'max_depth': 15,\n",
        "    'learning_rate': 0.008393206404444,\n",
        "    'min_data_in_leaf': 10,\n",
        "    'feature_fraction': 0.636593633990795,\n",
        "    'bagging_fraction': 0.8763178958731057,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 3.37372395608384,\n",
        "    'lambda_l2': 3.5508540427910322\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"FrontWing_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'FrontWing_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "ieCZQARc22jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Suspension\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "prac_df = pd.read_csv(\"practice_data_newnamesV3_2.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df[['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width']]\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 52,\n",
        "    'max_depth': 14,\n",
        "    'learning_rate': 0.02166755029862027,\n",
        "    'min_data_in_leaf': 10,\n",
        "    'feature_fraction': 0.5221020637935397,\n",
        "    'bagging_fraction': 0.938010385446846,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 2.531857885425292,\n",
        "    'lambda_l2': 4.788757729441045\n",
        "    }\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Suspension_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Suspension_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "z34fB37822jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Brake Balance (hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "prac_df = pd.read_csv(\"practice_data_newnamesV3_2.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df[['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine','Cornering', 'Width', 'Roughness', 'Temperature']]\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 27,\n",
        "    'max_depth': 11,\n",
        "    'learning_rate': 0.18696777761444966,\n",
        "    'min_data_in_leaf': 73,\n",
        "    'feature_fraction': 0.964098272670725,\n",
        "    'bagging_fraction': 0.8852821315081366,\n",
        "    'bagging_freq': 10,\n",
        "    'lambda_l1': 3.486399193949678,\n",
        "    'lambda_l2': 3.7053586457221366\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"BrakeBalance_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'BrakeBalance_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "qqzx4ff922jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and saving LGBM-Models for each Car-Parameter (Not SimPrac Combo)"
      ],
      "metadata": {
        "id": "vdpD1FdhGKsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Engine (Hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure' , 'Cornering']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 281,\n",
        "    'max_depth': 11,\n",
        "    'learning_rate': 0.04083240077095524,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9534759457760267,\n",
        "    'bagging_fraction': 0.6637656869307713,\n",
        "    'bagging_freq': 7,\n",
        "    'lambda_l1': 0.48486124811843856,\n",
        "    'lambda_l2': 1.0469435993282974\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Engine_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Engine_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "kBMC0Tg7GCxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Differential (Hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 126,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05725939263903659,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9048274481436259,\n",
        "    'bagging_fraction': 0.6871315558035545,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 2.9809700145880162,\n",
        "    'lambda_l2': 2.893530172381254\n",
        "    }\n",
        "\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Differential_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Differential_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "eUDpQqMbGCxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rear Wing (Hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure' , 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 41,\n",
        "    'max_depth': 14,\n",
        "    'learning_rate': 0.07379289439034513,\n",
        "    'min_data_in_leaf': 14,\n",
        "    'feature_fraction': 0.9805583874353474,\n",
        "    'bagging_fraction': 0.757494844528942,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 3.3280185770912905,\n",
        "    'lambda_l2': 4.668868493827121\n",
        "    }\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"RearWing_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'RearWing_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "yqQMVK1pGCxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Front Wing (hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 228,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.10991909073754202,\n",
        "    'min_data_in_leaf': 94,\n",
        "    'feature_fraction': 0.954670793846081,\n",
        "    'bagging_fraction': 0.7659843231590522,\n",
        "    'bagging_freq': 1, 'lambda_l1': 3.8616883301361553,\n",
        "    'lambda_l2': 4.896984209036385\n",
        "    }\n",
        "\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"FrontWing_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'FrontWing_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "8oUuJxikGCxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Suspension\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': 10,\n",
        "    'learning_rate': 0.14051851191638579,\n",
        "    'min_data_in_leaf': 75,\n",
        "    'feature_fraction': 0.999888882811791,\n",
        "    'bagging_fraction': 0.7009625088481276,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 4.8851994495913145,\n",
        "    'lambda_l2': 3.6824821872767783\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"Suspension_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'Suspension_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "hkBpHrzUGCxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Brake Balance (hyperparameters and X set)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data_newnames.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df[['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine','Cornering', 'Width', 'Roughness', 'Temperature']]\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 27,\n",
        "    'max_depth': 11,\n",
        "    'learning_rate': 0.18696777761444966,\n",
        "    'min_data_in_leaf': 73,\n",
        "    'feature_fraction': 0.964098272670725,\n",
        "    'bagging_fraction': 0.8852821315081366,\n",
        "    'bagging_freq': 10,\n",
        "    'lambda_l1': 3.486399193949678,\n",
        "    'lambda_l2': 3.7053586457221366\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"BrakeBalance_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'BrakeBalance_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "LWq7AZI4GCxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing Models using Practice Data"
      ],
      "metadata": {
        "id": "xRwa1wATpFuc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kO_PDP2UpD-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Model names\n",
        "model_names = [\n",
        "    \"Engine_lgbm_model_R3.txt\",\n",
        "    \"Differential_lgbm_model_R3.txt\",\n",
        "    \"RearWing_lgbm_model_R3.txt\",\n",
        "    \"FrontWing_lgbm_model_R3.txt\",\n",
        "    \"Suspension_lgbm_model_R3.txt\",\n",
        "    \"BrakeBalance_lgbm_model_R3.txt\"\n",
        "]\n",
        "\n",
        "# Corresponding feature sets\n",
        "feature_sets = {\n",
        "    \"Engine\": ['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure', 'Cornering'],\n",
        "    \"Differential\": ['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density'],\n",
        "    \"RearWing\": ['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness'],\n",
        "    \"FrontWing\": ['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)'],\n",
        "    \"Suspension\": ['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width'],\n",
        "    \"BrakeBalance\": ['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Width', 'Roughness', 'Temperature']\n",
        "}\n",
        "\n",
        "# Load new data\n",
        "df = pd.read_csv(\"practice_data_newnamesV3_1.csv\")\n",
        "\n",
        "# Compute Avg Speed for new data\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Target variable\n",
        "y_new = df[\"Avg Speed\"]\n",
        "\n",
        "# Sample weight\n",
        "sample_weight = [1000] * len(y_new)\n",
        "\n",
        "# Training each model with its feature set\n",
        "for model_file in model_names:\n",
        "    model_key = model_file.split(\"_\")[0]  # Extract the prefix e.g., \"Engine\"\n",
        "    features = feature_sets[model_key]\n",
        "\n",
        "    print(f\"\\nUpdating {model_file} with features: {features}\")\n",
        "\n",
        "    # Prepare feature matrix\n",
        "    X_new = df[features]\n",
        "\n",
        "    # Load existing model\n",
        "    model = lgb.Booster(model_file=model_file)\n",
        "\n",
        "    # Create dataset\n",
        "    new_data = lgb.Dataset(X_new, label=y_new, weight=sample_weight)\n",
        "\n",
        "    # Continue training\n",
        "    updated_model = lgb.train(\n",
        "        params={},\n",
        "        train_set=new_data,\n",
        "        init_model=model,\n",
        "        num_boost_round=1000\n",
        "    )\n",
        "\n",
        "    # Save updated model\n",
        "    updated_file = model_file.replace(\".txt\", \"_updated.txt\")\n",
        "    updated_model.save_model(updated_file)\n",
        "\n",
        "    print(f\"Model saved to {updated_file}\")\n",
        "\n",
        "print(\"\\nAll models updated successfully.\")\n"
      ],
      "metadata": {
        "id": "Sfes5lvwpEe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequentially optimizing Car Parameters."
      ],
      "metadata": {
        "id": "YNPkq8hpIhzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "useTt8vJI-S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "# Ordered list of parameters to optimize\n",
        "params_to_optimize = [\"Engine\", \"Differential\", \"RearWing\", \"FrontWing\", \"Suspension\", \"BrakeBalance\"]\n",
        "\n",
        "# Corresponding feature sets for each model\n",
        "feature_sets = {\n",
        "    \"Engine\": ['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure', 'Cornering'],\n",
        "    \"Differential\": ['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density'],\n",
        "    \"RearWing\": ['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness'],\n",
        "    \"FrontWing\": ['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)'],\n",
        "    \"Suspension\": ['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width'],\n",
        "    \"BrakeBalance\": ['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Width', 'Roughness', 'Temperature']\n",
        "}\n",
        "\n",
        "# Load static track & weather data\n",
        "base_data = pd.read_csv(\"track_weather_netherlands.csv\")\n",
        "\n",
        "# This will hold the best parameter values as we optimize them\n",
        "optimized_params = {}\n",
        "\n",
        "# Begin sequential optimization\n",
        "for car_part in params_to_optimize:\n",
        "    print(f\"\\n🔧 Optimizing {car_part}...\")\n",
        "\n",
        "    model_path = f\"{car_part}_lgbm_model_R3.txt\"\n",
        "    model = lgb.Booster(model_file=model_path)\n",
        "    features = feature_sets[car_part]\n",
        "\n",
        "    def objective(trial):\n",
        "        # Set the current parameter being optimized\n",
        "\n",
        "        params = {\n",
        "            \"Engine\": trial.suggest_int(\"Engine\", 1, 500),\n",
        "            \"RearWing\": trial.suggest_int(\"RearWing\", 1, 500),\n",
        "            \"FrontWing\": trial.suggest_int(\"FrontWing\", 1, 500),\n",
        "            \"BrakeBalance\": trial.suggest_int(\"BrakeBalance\", 1, 500),\n",
        "            \"Suspension\": trial.suggest_int(\"Suspension\", 1, 500),\n",
        "            \"Differential\": trial.suggest_int(\"Differential\", 1, 500),}\n",
        "\n",
        "        current_value = params[car_part]\n",
        "\n",
        "        # Create a single row input with all needed features\n",
        "        input_data = base_data.copy()\n",
        "\n",
        "        # Add previously optimized params\n",
        "        for param, value in optimized_params.items():\n",
        "            input_data[param] = value\n",
        "\n",
        "        # Add current trial value\n",
        "        input_data[car_part] = current_value\n",
        "\n",
        "        # If any missing feature, fill with 0 or a safe default\n",
        "        for col in features:\n",
        "            if col not in input_data.columns:\n",
        "                input_data[col] = 0\n",
        "\n",
        "        # Ensure correct order of features\n",
        "        X = input_data[features]\n",
        "\n",
        "        # Predict Avg Speed\n",
        "        avg_speed = model.predict(X)[0]\n",
        "        return avg_speed  # Optuna maximizes this\n",
        "\n",
        "    # Run Optuna\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=500, show_progress_bar=True)\n",
        "\n",
        "    best_value = study.best_params[car_part]\n",
        "    optimized_params[car_part] = best_value\n",
        "    print(f\"✅ Best {car_part}: {best_value}\")\n",
        "\n",
        "# Final results\n",
        "print(\"\\n🎯 Final Optimized Parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "5PvVj0gTIrPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "🎯 Final Optimized Parameters:\n",
        "Engine: 77\n",
        "Differential: 101\n",
        "RearWing: 161\n",
        "FrontWing: 80\n",
        "Suspension: 41\n",
        "BrakeBalance: 68\n",
        "\n",
        "🎯 Final Optimized Parameters:\n",
        "Engine: 45\n",
        "Differential: 35\n",
        "RearWing: 233\n",
        "FrontWing: 72\n",
        "Suspension: 160\n",
        "BrakeBalance: 53"
      ],
      "metadata": {
        "id": "-o_VKmAcknpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "# Ordered list of car parameters to optimize\n",
        "params_to_optimize = [\n",
        "    \"Engine\", \"Differential\", \"RearWing\",\n",
        "    \"FrontWing\", \"Suspension\", \"BrakeBalance\"\n",
        "]\n",
        "\n",
        "# Feature sets used by each model for prediction\n",
        "feature_sets = {\n",
        "    \"Engine\": ['Engine', 'Grip', 'Humidity', 'Air Density', 'Altitude', 'Temperature', 'Inclines', 'Air Pressure', 'Cornering'],\n",
        "    \"Differential\": ['Differential', 'Engine', 'Cornering', 'Width', 'Inclines', 'Grip', 'Temperature', 'Air Density'],\n",
        "    \"RearWing\": ['RearWing', 'Differential', 'Engine', 'Air Density', 'Cornering', 'Air Pressure', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Roughness'],\n",
        "    \"FrontWing\": ['FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Air Pressure', 'Air Density', 'Inclines', 'Wind (Avg. Speed)', 'Humidity', 'Wind (Gusts)'],\n",
        "    \"Suspension\": ['Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Grip', 'Inclines', 'Cornering', 'Camber', 'Roughness', 'Width'],\n",
        "    \"BrakeBalance\": ['BrakeBalance', 'Suspension', 'FrontWing', 'RearWing', 'Differential', 'Engine', 'Cornering', 'Width', 'Roughness', 'Temperature']\n",
        "}\n",
        "\n",
        "# Load static base data (track & weather)\n",
        "base_data = pd.read_csv(\"track_weather_netherlands.csv\")\n",
        "\n",
        "# Dictionary to store optimized values\n",
        "optimized_params = {}\n",
        "\n",
        "# Sequential optimization loop\n",
        "for car_part in params_to_optimize:\n",
        "    print(f\"\\n🔧 Optimizing {car_part}...\")\n",
        "\n",
        "    # Load the pretrained LightGBM model\n",
        "    model = lgb.Booster(model_file=f\"{car_part}_lgbm_model_R3.txt\")\n",
        "    features = feature_sets[car_part]\n",
        "\n",
        "    def objective(trial):\n",
        "        # Clone base data for this trial\n",
        "        input_data = base_data.copy()\n",
        "\n",
        "        # Add fixed parameters (already optimized)\n",
        "        for param, value in optimized_params.items():\n",
        "            input_data[param] = value\n",
        "\n",
        "        # Suggest value only for the current parameter\n",
        "        trial_value = trial.suggest_int(car_part, 1, 500)\n",
        "        input_data[car_part] = trial_value\n",
        "\n",
        "        # Fill in missing feature columns with default (0)\n",
        "        for feature in features:\n",
        "            if feature not in input_data.columns:\n",
        "                input_data[feature] = 0\n",
        "\n",
        "        # Predict average speed\n",
        "        X = input_data[features]\n",
        "        avg_speed = model.predict(X)[0]\n",
        "        return avg_speed\n",
        "\n",
        "    # Run Optuna optimization for this parameter\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
        "\n",
        "    # Save best value\n",
        "    best_value = study.best_params[car_part]\n",
        "    optimized_params[car_part] = best_value\n",
        "    print(f\"✅ Best {car_part}: {best_value}\")\n",
        "\n",
        "# Final results\n",
        "print(\"\\n🎯 Final Optimized Parameters:\")\n",
        "for k, v in optimized_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "a665N6bAmqWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AllInOne Optimization"
      ],
      "metadata": {
        "id": "3o5jS5VRDBwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"simulator_data.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "df[\"Avg Speed\"] = (df[\"Lap Distance\"] / df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "\n",
        "# Define LightGBM dataset\n",
        "lgb_data = lgb.Dataset(X, label=y)\n",
        "\n",
        "# Parameters (tuned already)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 242,\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.0645474493988489,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9427185636727835,\n",
        "    'bagging_fraction': 0.785711983453578,\n",
        "    'bagging_freq': 2,\n",
        "    'lambda_l1': 0.6006835353397709,\n",
        "    'lambda_l2': 1.4905819957883624,\n",
        "}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"best_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'best_lgbm_model_R3.txt'\")\n"
      ],
      "metadata": {
        "id": "CsuSmP2-DIbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Directly trained LGBM-Model with Simulator_Data and Practice_data using optm. Hyperparameters\n",
        "#Hyperparameters optm. for Simulator and Practice_data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load both datasets\n",
        "sim_df = pd.read_csv(\"simulator_data.csv\")\n",
        "prac_df = pd.read_csv(\"practice_dataV3_2.csv\")\n",
        "\n",
        "# Compute Avg Speed\n",
        "sim_df[\"Avg Speed\"] = (sim_df[\"Lap Distance\"] / sim_df[\"Lap Time\"]) * 3600\n",
        "prac_df[\"Avg Speed\"] = (prac_df[\"Lap Distance\"] / prac_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Assign weights\n",
        "sim_df[\"weight\"] = 1.0\n",
        "prac_df[\"weight\"] = 250.0\n",
        "\n",
        "# Make sure both have the same columns in the same order\n",
        "required_cols = [\"Lap Distance\", \"Lap Time\", \"Avg Speed\", \"weight\", \"Rear Wing\", \"Front Wing\", \"Engine\", \"Brake Balance\", \"Differential\", \"Suspension\", \"Cornering\", \"Inclines\", \"Camber\", \"Grip\", \"Altitude\", \"Roughness\", \"Width\", \"Temperature\", \"Humidity\", \"Wind (Avg. Speed)\", \"Wind (Gusts)\", \"Air Density\", \"Air Pressure\"] + \\\n",
        "                [col for col in sim_df.columns if col not in [\"Lap Distance\", \"Lap Time\", \"Avg Speed\", \"weight\", \"Rear Wing\", \"Front Wing\", \"Engine\", \"Brake Balance\", \"Differential\", \"Suspension\", \"Cornering\", \"Inclines\", \"Camber\", \"Grip\", \"Altitude\", \"Roughness\", \"Width\", \"Temperature\", \"Humidity\", \"Wind (Avg. Speed)\", \"Wind (Gusts)\", \"Air Density\", \"Air Pressure\"]]\n",
        "\n",
        "sim_df = sim_df[required_cols]\n",
        "prac_df = prac_df[required_cols]\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([sim_df, prac_df], ignore_index=True)\n",
        "\n",
        "# Features, target, and weights\n",
        "X = df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\", \"weight\"])\n",
        "y = df[\"Avg Speed\"]\n",
        "weights = df[\"weight\"]\n",
        "\n",
        "# Define LightGBM dataset with weights\n",
        "lgb_data = lgb.Dataset(X, label=y, weight=weights)\n",
        "\n",
        "# Parameters (already tuned)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 74,\n",
        "    'max_depth': 11,\n",
        "    'learning_rate': 0.028870630893942515,\n",
        "    'min_data_in_leaf': 13,\n",
        "    'feature_fraction': 0.7399238619191133,\n",
        "    'bagging_fraction': 0.9203471068533383,\n",
        "    'bagging_freq': 6,\n",
        "    'lambda_l1': 0.025758523534949052,\n",
        "    'lambda_l2': 0.9073066525703107}\n",
        "\n",
        "# Train on full dataset\n",
        "model = lgb.train(params, lgb_data, num_boost_round=1000)\n",
        "\n",
        "# Save the model to a file\n",
        "model.save_model(\"sim_prac_lgbm_model_R3.txt\")\n",
        "\n",
        "print(\"Model training complete and saved to 'sim_prac_lgbm_model_R3.txt'\")"
      ],
      "metadata": {
        "id": "cXVlcXoLuwI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load the original model\n",
        "model = lgb.Booster(model_file=\"best_lgbm_model_R3.txt\")\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'l2',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 242,\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.0645474493988489,\n",
        "    'min_data_in_leaf': 96,\n",
        "    'feature_fraction': 0.9427185636727835,\n",
        "    'bagging_fraction': 0.785711983453578,\n",
        "    'bagging_freq': 2,\n",
        "    'lambda_l1': 0.6006835353397709,\n",
        "    'lambda_l2': 1.4905819957883624,\n",
        "}\n",
        "# Load the new data\n",
        "new_df = pd.read_csv(\"practice_dataV3_1.csv\")\n",
        "\n",
        "# Compute Avg Speed for new data\n",
        "new_df[\"Avg Speed\"] = (new_df[\"Lap Distance\"] / new_df[\"Lap Time\"]) * 3600\n",
        "\n",
        "# Prepare features and target\n",
        "X_new = new_df.drop(columns=[\"Avg Speed\", \"Lap Distance\", \"Lap Time\",\"Round\", \"Track\", \"Qualifying\", \"Stint\", \"Lap\", \"Fuel\", \"Tyre Remaining\", \"Tyre Choice\"])\n",
        "y_new = new_df[\"Avg Speed\"]\n",
        "\n",
        "# Assign higher weights (e.g., 10x more important)\n",
        "sample_weight = [5] * len(y_new)\n",
        "\n",
        "# Create new LightGBM Dataset\n",
        "new_data = lgb.Dataset(X_new, label=y_new, weight=sample_weight)\n",
        "\n",
        "# Continue training from previous model\n",
        "model = lgb.train(\n",
        "    params={},  # Empty here since model already knows them\n",
        "    train_set=new_data,\n",
        "    init_model=model,\n",
        "    num_boost_round=1000,  # You can increase if needed\n",
        ")\n",
        "\n",
        "# Save updated model\n",
        "model.save_model(\"best_lgbm_model_R3_updated.txt\")\n",
        "\n",
        "print(\"Model updated with new data and saved to 'best_lgbm_model_R3_updated.txt'\")\n"
      ],
      "metadata": {
        "id": "OKMKqN_CEjMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4jHnxt6gDbLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "\n",
        "# Load trained model\n",
        "#model = lgb.Booster(model_file=\"best_lgbm_model_R3_updated.txt\")\n",
        "model = lgb.Booster(model_file=\"sim_prac_lgbm_model_R3.txt\")\n",
        "\n",
        "# Load track/weather data (single row)\n",
        "track_weather = pd.read_csv(\"track_weather_netherlands.csv\")\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    # Suggest car parameters\n",
        "    params = {\n",
        "        \"Engine\": trial.suggest_int(\"Engine\", 20, 60),\n",
        "        \"Rear Wing\": trial.suggest_int(\"Rear Wing\", 200, 300),\n",
        "        \"Front Wing\": trial.suggest_int(\"Front Wing\", 48, 88),\n",
        "        \"Brake Balance\": trial.suggest_int(\"Brake Balance\", 18, 118),\n",
        "        \"Suspension\": trial.suggest_int(\"Suspension\", 10, 110),\n",
        "        \"Differential\": trial.suggest_int(\"Differential\", 10, 100),\n",
        "    }\n",
        "\n",
        "#Engine: 45\n",
        "#RearWing: 250\n",
        "#FrontWing: 68\n",
        "#BrakeBalance: 68\n",
        "#Suspension: 60\n",
        "#Differential: 35\n",
        "\n",
        "    # Combine with static track/weather parameters\n",
        "    input_data = pd.concat([track_weather, pd.DataFrame([params])], axis=1)\n",
        "\n",
        "    # Predict average speed\n",
        "    predicted_avg_speed = model.predict(input_data)[0]\n",
        "\n",
        "    # We want to maximize speed\n",
        "    return -predicted_avg_speed\n",
        "\n",
        "# Create study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "\n",
        "# Optimize\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Output best results\n",
        "best_trial = study.best_trial\n",
        "print(\"\\nBest Parameters:\")\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "print(f\"Predicted Avg Speed: {-best_trial.value:.2f}\")"
      ],
      "metadata": {
        "id": "CeWJlFASDbxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Race Strategy"
      ],
      "metadata": {
        "id": "0iREpS-7e4vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Define the tire parameters and their lap time formulas\n",
        "def lap_time_super_soft(X):\n",
        "    return (78.0565192575555) + 0.114973111111111 * X\n",
        "\n",
        "def lap_time_soft(X):\n",
        "    return (78.8737020908889) + 0.136290277777778 * X\n",
        "\n",
        "def lap_time_medium(X):\n",
        "    return (79.1300868242222) + 0.131553711111111 * X\n",
        "\n",
        "def lap_time_hard(X):\n",
        "    return (79.2600146591429) + 0.137075542857143 * X\n",
        "\n",
        "# Tire data with their lifespan\n",
        "tire_lifespan = {\n",
        "    \"super_soft\": 12,\n",
        "    \"soft\": 24,\n",
        "    \"medium\": 30,\n",
        "    \"hard\": 35\n",
        "}\n",
        "\n",
        "# Pit stop penalty\n",
        "pit_stop_time = 30  # seconds\n",
        "\n",
        "# Function to calculate the total race time for a given strategy\n",
        "def calculate_race_time(laps, strategy):\n",
        "    total_time = 0\n",
        "    total_pit_stops = 0\n",
        "    lap_index = 0\n",
        "    lap_counter = 0\n",
        "\n",
        "    while lap_counter < laps:\n",
        "        tire, stint_laps = strategy[lap_index]\n",
        "\n",
        "        # Ensure we don't exceed the total laps\n",
        "        if lap_counter + stint_laps > laps:\n",
        "            stint_laps = laps - lap_counter\n",
        "\n",
        "        # Calculate the lap times for this stint\n",
        "        lap_times = []\n",
        "        for i in range(stint_laps):\n",
        "            if tire == \"super_soft\":\n",
        "                lap_times.append(lap_time_super_soft(i + 1))\n",
        "            elif tire == \"soft\":\n",
        "                lap_times.append(lap_time_soft(i + 1))\n",
        "            elif tire == \"medium\":\n",
        "                lap_times.append(lap_time_medium(i + 1))\n",
        "            elif tire == \"hard\":\n",
        "                lap_times.append(lap_time_hard(i + 1))\n",
        "\n",
        "        total_time += sum(lap_times)  # Add the lap times of this stint\n",
        "        lap_counter += stint_laps\n",
        "\n",
        "        # If we are not at the last stint, account for a pit stop\n",
        "        if lap_counter < laps:\n",
        "            total_time += pit_stop_time  # Pit stop penalty\n",
        "            total_pit_stops += 1\n",
        "\n",
        "        lap_index += 1\n",
        "        if lap_index >= len(strategy):\n",
        "            break\n",
        "\n",
        "    return total_time, total_pit_stops\n",
        "\n",
        "# Function to generate possible strategies dynamically\n",
        "def generate_strategies(laps):\n",
        "    strategies = []\n",
        "    tire_choices = [\"super_soft\", \"soft\", \"medium\", \"hard\"]\n",
        "\n",
        "    # Generate strategies by breaking the laps into multiple stints\n",
        "    for tire1 in tire_choices:\n",
        "        for tire2 in tire_choices:\n",
        "            for tire3 in tire_choices:\n",
        "                for tire4 in tire_choices:\n",
        "                  for tire5 in tire_choices:\n",
        "                    strategy = []\n",
        "                    remaining_laps = laps\n",
        "\n",
        "                    # Create dynamic stints for each tire\n",
        "                    for tire in [tire1, tire2, tire3, tire4, tire5]:\n",
        "                    #for tire in [tire1, tire2, tire3, tire4]:\n",
        "                    #for tire in [tire1, tire2, tire3]:\n",
        "                    #for tire in [tire1, tire2]:\n",
        "                        stint_laps = tire_lifespan[tire]\n",
        "\n",
        "                        if remaining_laps > stint_laps:\n",
        "                            strategy.append((tire, stint_laps))\n",
        "                            remaining_laps -= stint_laps\n",
        "                        else:\n",
        "                            strategy.append((tire, remaining_laps))\n",
        "                            break\n",
        "\n",
        "                    if sum([stint[1] for stint in strategy]) == laps:\n",
        "                        strategies.append(strategy)\n",
        "\n",
        "    return strategies\n",
        "\n",
        "# Function to find the best strategy\n",
        "def optimize_strategy(laps):\n",
        "    best_time = math.inf\n",
        "    best_strategy = None\n",
        "\n",
        "    strategies = generate_strategies(laps)\n",
        "\n",
        "    for strategy in strategies:\n",
        "        total_time, pit_stops = calculate_race_time(laps, strategy)\n",
        "        if total_time < best_time:\n",
        "            best_time = total_time\n",
        "            best_strategy = strategy\n",
        "            best_pit_stops = pit_stops\n",
        "\n",
        "    return best_strategy, best_time, best_pit_stops\n",
        "\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    race_laps = 75\n",
        "    best_strategy, best_time, total_pit_stops = optimize_strategy(race_laps)\n",
        "    print(f\"Best Strategy: {best_strategy}\")\n",
        "    print(f\"Best Total Time: {best_time} seconds\")\n",
        "    print(f\"Total Pit Stops: {total_pit_stops}\")"
      ],
      "metadata": {
        "id": "dxJNdgFCe4vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFETMTcZQL5T"
      },
      "source": [
        "# **Analytics for Race 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights Calculation"
      ],
      "metadata": {
        "id": "BzB4p5mRFVkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rbf_weights.py  –  einmal pro Race ausführen\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import mahalanobis          # RBF-Distanz\n",
        "\n",
        "META_COLS = [                                           # Ähnlichkeits-Features\n",
        "    \"Cornering\", \"Inclines\", \"Camber\", \"Grip\",\n",
        "    \"Altitude\", \"Roughness\", \"Width\",\n",
        "    \"Temperature\", \"Humidity\",\n",
        "    \"Wind (Avg. Speed)\", \"Wind (Gusts)\",\n",
        "    \"Air Density\", \"Air Pressure\"\n",
        "]\n",
        "\n",
        "def build_dataset_with_rbf(sim_csv, practice_csv,\n",
        "                           tau=2.0, practice_weight=5.0):\n",
        "    \"\"\"\n",
        "    liest Sim- und Practice-CSV ein, berechnet RBF-Gewichte\n",
        "    und gibt (DataFrame_all, weight_array) zurück.\n",
        "    \"\"\"\n",
        "    df_sim = pd.read_csv(sim_csv)\n",
        "    df_pr  = pd.read_csv(practice_csv)\n",
        "\n",
        "    # -- RBF-Kernel auf den Meta-Features ------------------\n",
        "    X_sim_meta = df_sim[META_COLS].values\n",
        "    X_pr_meta  = df_pr[META_COLS].values\n",
        "    centroid   = X_pr_meta.mean(axis=0)\n",
        "    Sigma_inv  = np.linalg.inv(np.cov(X_sim_meta, rowvar=False))\n",
        "\n",
        "    k_sim = np.exp([                                   # k_i = exp(-d_i / τ)\n",
        "        -mahalanobis(x, centroid, Sigma_inv) / tau\n",
        "        for x in X_sim_meta\n",
        "    ])                                                 # :contentReference[oaicite:0]{index=0}\n",
        "\n",
        "    w_sim = k_sim\n",
        "    w_pr  = np.full(len(df_pr), practice_weight)\n",
        "\n",
        "    weights = np.concatenate([w_sim, w_pr])\n",
        "    df_all  = pd.concat([df_sim, df_pr], ignore_index=True)\n",
        "\n",
        "    return df_all, weights\n"
      ],
      "metadata": {
        "id": "7aiQLQCLFiES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------\n",
        "# Schritt 0: Daten + Gewichte laden\n",
        "# -------------------------------------------------------\n",
        "from rbf_weights import build_dataset_with_rbf\n",
        "\n",
        "df_all, weights = build_dataset_with_rbf(\n",
        "    \"simulator_data_newnames.csv\",\n",
        "    \"practice_data.csv\",      # deine echte 80-Lap-Datei\n",
        "    tau=2.0,                  # Bandbreite feiner / gröber stellen\n",
        "    practice_weight=5.0       # konstantes Gewicht der 80 Laps\n",
        ")\n",
        "\n",
        "# gemeinsame Zielvariable\n",
        "df_all[\"Avg Speed\"] = (df_all[\"Lap Distance\"] / df_all[\"Lap Time\"]) * 3600\n"
      ],
      "metadata": {
        "id": "pLbKdGgsGiV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS0Om6gBQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ajs8np_QL5T"
      },
      "source": [
        "# **Analytics for Race 5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfLSArfnQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFvVYCufQL5T"
      },
      "source": [
        "## **Debrief Race Calendar before Final Race**\n",
        "\n",
        "*Write a longer text (200-500 words) reflecting on what were the main ideas you started the seminar with, how you improved your models to achieve better performance and what strategy and analytics you want to use for your final race during seminar day*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1t67p2kQL5T"
      },
      "source": [
        "## **Analytics for Final Race**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVrrOFguQL5T"
      },
      "outputs": [],
      "source": [
        "# Team members working on this code: Names.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kulv8cpKcq9_"
      },
      "source": [
        "## **References**\n",
        "- Cite all references you need according to chair guidelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OLrMDxWc8oM"
      },
      "source": [
        "Liu, Xuan; Shi, Savannah Wei; Teixeira, Thales; Wedel, Michel (2018): Video Content Marketing: The Making of Clips, Journal of Marketing, Vol. 82, 86-101."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}